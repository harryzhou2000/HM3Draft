%% 
%% Copyright 2007-2020 Elsevier Ltd
%% 
%% This file is part of the 'Elsarticle Bundle'.
%% ---------------------------------------------
%% 
%% It may be distributed under the conditions of the LaTeX Project Public
%% License, either version 1.2 of this license or (at your option) any
%% later version.  The latest version of this license is in
%%    http://www.latex-project.org/lppl.txt
%% and version 1.2 or later is part of all distributions of LaTeX
%% version 1999/12/01 or later.
%% 
%% The list of all files belonging to the 'Elsarticle Bundle' is
%% given in the file `manifest.txt'.
%% 

%% Template article for Elsevier's document class `elsarticle'
%% with numbered style bibliographic references
%% SP 2008/03/01
%%
%% 
%%
%% $Id: elsarticle-template-num.tex 190 2020-11-23 11:12:32Z rishi $
%%
%%
\documentclass[preprint,12pt]{elsarticle}

%% Use the option review to obtain double line spacing
%% \documentclass[authoryear,preprint,review,12pt]{elsarticle}

%% Use the options 1p,twocolumn; 3p; 3p,twocolumn; 5p; or 5p,twocolumn
%% for a journal layout:
%% \documentclass[final,1p,times]{elsarticle}
%% \documentclass[final,1p,times,twocolumn]{elsarticle}
%% \documentclass[final,3p,times]{elsarticle}
%% \documentclass[final,3p,times,twocolumn]{elsarticle}
%% \documentclass[final,5p,times]{elsarticle}
%% \documentclass[final,5p,times,twocolumn]{elsarticle}

%% For including figures, graphicx.sty has been loaded in
%% elsarticle.cls. If you prefer to use the old commands
%% please give \usepackage{epsfig}

%% The amssymb package provides various useful mathematical symbols
\usepackage{amssymb}
\usepackage{amsmath}
%% The amsthm package provides extended theorem environments
%% \usepackage{amsthm}

%% The lineno packages adds line numbers. Start line numbering with
%% \begin{linenumbers}, end it with \end{linenumbers}. Or switch it on
%% for the whole article with \linenumbers.
%% \usepackage{lineno}

\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
    }
\usepackage{subcaption}

\journal{Journal's Name}

\begin{document}

\begin{frontmatter}

    %% Title, authors and addresses

    %% use the tnoteref command within \title for footnotes;
    %% use the tnotetext command for theassociated footnote;
    %% use the fnref command within \author or \address for footnotes;
    %% use the fntext command for theassociated footnote;
    %% use the corref command within \author for corresponding author footnotes;
    %% use the cortext command for theassociated footnote;
    %% use the ead command for the email address,
    %% and the form \ead[url] for the home page:
    \title{An Efficient Implicit Runge-Kutta Method
        Based on Time Interpolation
        for High-order Finite Volume Method}
    % \tnotetext[label1]{}
    % \ead{email address}
    % \ead[url]{home page}
    % \fntext[label2]{}
    % \cortext[cor1]{}
    % \fntext[label3]{}



    %% use optional labels to link authors explicitly to addresses:
    %% \author[label1,label2]{}
    %% \affiliation[label1]{organization={},
    %%             addressline={},
    %%             city={},
    %%             postcode={},
    %%             state={},
    %%             country={}}
    %%
    %% \affiliation[label2]{organization={},
    %%             addressline={},
    %%             city={},
    %%             postcode={},
    %%             state={},
    %%             country={}}

    \author[THUDEM]{Hanyu Zhou}
    \author[THUDEM]{Yuxin Ren}

    \affiliation[THUDEM]
    {
        organization=
            { Department of Engineering Mechanices, Tsinghua Universiy},%Department and Organization
        addressline={},
        city={},
        postcode={},
        state={Beijing},
        country={China}}



    \begin{abstract}
        Text of abstract

    \end{abstract}

    % %%Graphical abstract
    % \begin{graphicalabstract}
    % %\includegraphics{grabs}
    % \end{graphicalabstract}

    %%Research highlights
    \begin{highlights}
        \item Research highlight 1
        \item Research highlight 2
    \end{highlights}

    \begin{keyword}
        %% keywords here, in the form: keyword \sep keyword

        %% PACS codes here, in the form: \PACS code \sep code

        %% MSC codes here, in the form: \MSC code \sep code
        %% or \MSC[2008] code \sep code (2000 is the default)

    \end{keyword}

\end{frontmatter}

%% \linenumbers

%% main text
\section{Introduction}
\label{sec:intro}

In computational fluid dynamics (CFD),
high-order numerical methods have the capability of
resolving complex flows effectively and efficiently,
which have been attracting great attention recently.
Popular high-order CFD methods, including discontinuous
Galerkin (DG) methods
\cite{reed1973triangularDG,
    BASSI1997251DG,
    BASSI1997267DG,
    cockburn1989DGII,
    cockburn2001rungeDG},
spectral volume
\cite{WANG2002210_SV}
and spectral difference
\cite{LIU2006780_SD} methods,
PnPm procedures
\cite{DUMBSER20088209_PNPM},
FR/CPR methods
\cite{huynh2007flux_FR,
    huynh2009reconstruction_FR,
    vincent2011new_FR,
    wang2009unifying_CPR},
and finite volume (FV) methods
\cite{wang2016compact_VR,
    wang2016compact1_VR,
    wang2017compact_VR,
    pan2018high_VR,
    zhang2019compact_VR,
    barth1990higher_FV,
    delanaye1999quadratic_FV,
    ollivier1997quasi_ENO,
    friedrich1998weighted_WENO,
    hu1999weighted_WENO,
    dumbser2007quadrature_WENO},
generally provides spacial discretization methods
which produce semi-discretized forms of the original
partial differential equations (PDEs).
The semi-discretized PDEs are
sets of first order ordinary
differential equations (ODEs),
which are usually further solved with
ODE integrators such as the
popular strong stability preserving
Runge-Kutta (SSPRK) methods
\cite{gottlieb2001strong_SSPRK}.

Although explicit ODE integrators
are simple and efficient in a wide range of
CFD problems,
the Courant-Friedrichs-Lewy (CFL) constraint
that limits physical time step in explicit
methods could make them inefficient in
notably inhomogeneous or anisotropic
transient flows,
such as wall-bounded turbulence.
Such inefficiency could be overcome by
applying implicit ODE methods with
sufficient stability.
Due to Dahlquist's second barrier
\cite{dahlquist1963special},
only second and first order multi-step ODE methods
could achieve $A$-stability, and
trapezoid rule not being $L$-stable,
only the $L$-stable
second-order backward differentiation formula (BDF2)
is extensively adopted in transient CFD problems.
Different from multi-step methods,
the single-step implicit Runge-Kutta (IRK) methods
with multiple internal stages
can achieve higher order of accuracy while
preserving stability \cite{butcher2016ODEBook}.
Among the IRK methods, fully coupled IRK methods
could achieve optimal order given number of stages,
but they require the solution of a nonlinear
system with its dimension multiple times larger
than the ODE, which could be especially
troublesome for its implementation in
CFD schemes.
Pazner and Persson
\cite{pazner2017stage}
made effort in efficiently solving
fully IRK methods with DG, and
Jameson \cite{jameson2017evaluation}
discussed how to adopt dual time stepping
into fully IRK.
As a result of the difficulties in the solution
of fully IRK methods,
singly diagonally implicit Runge-Kutta (SDIRK)
methods are more commonly used in CFD, for example in
\cite{wang2017compact_VR}.
SDIRK methods have lower-triangular butcher tableau,
enabling the stage values to be solved in a sequence.
As a special case of SDIRK,
ESDIRK methods are SDIRK with an explicit first stage,
which are constructed to have 
stage order of 2 and $L$-stable
\cite{kennedy2003additiveARK,kvaerno2004singly}.
High-order ESDIRK schemes and
BDF2 have been tested in
\cite{
    bijl2002implicitBDFvESDIRK,
    wang2007implicitDGTests}
to solve flow problems,
whose results illustrate
better accuracy and higher efficiency
of high-order ESDIRK methods
compared to second order BDF2.

Apart from fully IRK and SDIRK methods,
another class of implicit RK methods,
mono implicit RK methods (MIRK)
\cite{cash1975classMIRKOrig}
have explicit internal stages and
puts all the implicitness into the final
stage, allowing the implicit system to
remain have the same number of dimensions
as the original ODE.
Cash and Signhal derived examples of
$A$-stable and $L$-stable high-order
MIRK methods in
\cite{cash1977clasMIRK1,cash1982monoMIRK2}.
Kulikov and Shindin presented a similar type
of method called nested implicit RK (NIRK)
\cite{kulikov2006familyNIRKOrig}.
Discussion was made on symmetry, stiff accuracy and
other advantageous properties of a series of Gauss type
NIRK methods.
\cite{kulikov2009adaptive}.
The major drawback of NIRK or MIRK schemes is that
the Jacobian matrices of the nonlinear algebraic problems
for each NIRK or MIRK step are
polynomials of the Jacobian of ODE's right hand side.
Cash and Singhal proposed to find MIRK methods whose
Jacobian could be factorized or approximate the Jacobian
with a factorization,
so that the Newton iteration
step could be solved by solving a series of successive linear
problems \cite{cash1982monoMIRK2}.
Kulikov and Shindin found certain factorization
approximation could sabotage the stability of
the method in
\cite{kulikov2009adaptive},
and analyzed how to choose the approximation of
Jacobian in
\cite{kulikov2007asymptotic}.
MIRK and NIRK methods are more attractive than SDIRK methods
for they require fewer inner stage solving.
Typical forth order
stiffly accurate ESDIRK requires 5 implicit internal stages to be
solved,
while MIRK and NIRK could
solve only one implicit stage.


MIRK and NIRK methods have less
implicit stages than SDIRK methods,
which gives them potential to gain better efficiency in
large scale problems.
However, current literature has seldom explored
the application of MIRK or NIRK methods in
PDE solving.
The fully IRK methods, on the hand,
have been practiced in
finite volume \cite{jameson2017evaluation} and
DG \cite{pazner2017stage}
as mentioned before,
but their implementations
in CFD methods are significantly more
complex compared to DIRK methods.

The current paper develops a single step implicit method HIRK
based on time interpolation,
and explores its implementation in high-order finite volume method.
The present research illustrates that the new time marching
method HIRK is equivalent with a implicit RK method with 3rd to 4th
order of accuracy, with high stage order.
Meanwhile, the current provides practical matrix-free
solving strategy for the implicit
algebraic problem
arising from HIRK time marching of high-order finite volume method.
In numerical tests with 2D Euler equation and NS equation,
the current paper demonstrates the potential of HIRK
to exceed the popular 4th order ESDIRK method in efficiency.
\#\#\#\#

Paper's structure:...%TODO

\section{High-order Compact Finite Volume Method}
\label{sec:CFV}

\newcommand{\U}{\mathbf{U}}
\newcommand{\F}{\mathbf{F}}
\newcommand{\x}{\mathbf{x}}

The new time-marching method developed in
the current paper, HIRK, is aimed to support
high-order finite volume method.
Therefore,
this section will provide a description of
finite volume spacial discretization,
and specify details
of the high-order finite volume scheme
used in numerical tests.

\subsection{Governing Equations}
\label{ssec:GovEq}

The compressible Navier-Stokes equations has the conservative form:
\begin{equation}
    \label{eq:NS}
    \frac{\partial \U}{\partial t} +
    (\F - \F_v) \cdot \mathbf\nabla = 0
\end{equation}
where $\U$ is vector of conservative quantities and
$\F=[\F_1,\F_2,\F_3]$,
$\F_v=[\F_{v,1},\F_{v,2},\F_{v,3}]$
are
inviscid and viscous tensors of
their flux.
In cartesian coordinates $x_k, k=1,2,3$, the components are
\begin{equation}
    \U = \begin{bmatrix}
        \rho \\ \rho u_1 \\ \rho u_2 \\ \rho u_3 \\ E
    \end{bmatrix},\ \
    \F_j = \begin{bmatrix}
        \rho u_j                   \\
        \rho u_1u_j + p\delta_{1j} \\
        \rho u_2u_j + p\delta_{2j} \\
        \rho u_3u_j + p\delta_{3j} \\
        (E+p)u_j                   \\
    \end{bmatrix},\ \
    \F_{v,j} = \begin{bmatrix}
        0                                \\
        \tau_{1j}                        \\
        \tau_{2j}                        \\
        \tau_{3j}                        \\
        \sum_{k=1}^3{u_k\tau_{kj}} - K_j \\
    \end{bmatrix}
\end{equation}
where $\rho$ is density,
$u_i, i=1,2,3$ are velocity components,
$p$ is pressure,
$E$ is total energy per unit volume,
$\tau_{ij}, i,j=1,2,3$ are viscous stress tensor components
and
$K_i, i=1,2,3$ are heat flux components.
$\delta_{ij}$ is
Kronecker delta.
With ideal gas equation of state,
Newtonian viscosity and Fourier
heat conduction, additional relations
\begin{equation}
    \begin{aligned}
        E         & = \frac{p}{\gamma -1 } + \frac{1}{2}\rho\sum_{k=1}^{3}(u_ku_k)  \\
        p         & =\rho R_g T                                                     \\
        \tau_{ij} & =
        \mu\left(\frac{\partial u_i}{\partial x_j} + \frac{\partial u_j}{\partial x_i}\right)
        -
        \frac{2}{3}\mu \delta_{ij}\sum_{k=1}^{3}{\frac{\partial u_k}{\partial x_k}} \\
        K_i       & = - \kappa \frac{\partial T}{\partial x_i}
    \end{aligned}
\end{equation}
are used to close the equations
with $T$ being temperature, $\gamma$ being specific heat ratio,
$R_g$ being  gas constant, $\mu$ being dynamic viscosity,
$\kappa$ being thermal conductivity.
Specific heat ratio $\gamma$ is fixed to $1.4$ in this paper.
The current paper only
considers using simple gas property
with $\kappa = \mu c_p / Pr$,
and $\mu=\mu_{\infty}$ being a constant,
while $c_p$ is special heat capacity
at constant pressure and
Prandtl number $Pr$ is fixed to 0.71 in this paper.
When $\mu=0$,
$\F_v=0$ and
equation \eqref{eq:NS} becomes Euler equation.
The equations discussed above are in 3D form, and
assuming constant distribution of values over $x_3$
yields the 2D version of NS and Euler equations.

\subsection{Finite Volume Spacial Discretization}
\label{ssec:FV}

\newcommand{\OO}{\mathbf{\Omega}}
\newcommand{\UM}{\overline{\U}}
\newcommand{\Fn}{\tilde{\F}}
\newcommand{\n}{\mathbf{n}}
\newcommand{\uu}{\overline{\mathbf{U}}}
\newcommand{\R}{\mathbf{R}}
\newcommand{\inc}{\mathrm\Delta}
\newcommand{\Tau}{\mathrm{T}}

This subsection provides a general framework of
high-order
finite volume discretization.
The computational domain $\OO$ is divided
into $N_{cell}$ cells $\OO_i, i=1,2,...N_{cell}$ which
are non-overlapping, forming a mesh.
An averaging of conservative quantities
over each cell is
\begin{equation}
    \label{eq:FVMean}
    \UM_j = \frac{1}{\overline{\OO}_j}\int_{\OO_j}\U(\x)dV
\end{equation}
where $\overline{\OO}_j$ is the volume of $\OO_j$.

Next, a degree $p$ piecewise polynomial reconstruction is
conducted to approximate the distribution of
quantities
\begin{equation}
    \label{eq:FVRec}
    \U_j(\x) = \UM_j + \sum_{i=1}^{\mathrm{NDOF}(p)}{\U_j^i\varphi_{j,i}(\x) }
\end{equation}
in which $\U_j(\x)$ is the local polynomial distribution on cell $j$,
and
$\varphi_{j,i}(\x)$ are
polynomial basis functions.
The current paper uses zero-mean Taylor basis
for reconstruction \cite{wang2017compact_VR}.
Given a specific reconstruction method,
the reconstruction coefficients $\U_j^i$ can be determined using
the distribution of mean value $\UM_k, k=1,2...N_{cell}$
and boundary conditions.

With the piecewise polynomial approximation,
the PDEs \eqref{eq:NS} can therefore become ODEs
with cell averaging applied
\begin{equation}
    \label{eq:FVInt}
    \frac{d\UM_i}{dt}
    +\sum_{j\in S_i, j\neq i}{\left(
        \int_{f_{i,j}}{
            [\Fn(\U_i,\U_j) - \Fn_v(\U_i,\U_j, \nabla \U_i, \nabla \U_j)] \cdot \n  dA
        }\right)
    }
    = 0
\end{equation}
where $\Fn(\U_i,\U_j)$ and $\Fn_v(\U_i,\U_j, \nabla \U_i, \nabla \U_j)$ are approximations
of exact fluxes on the cell interfaces,
and $f_{i,j}=\OO_i \cap \OO_j$ is the interface between $i,j$ cells.
Set $S_i$ denotes the compact stencil of cell $i$.
The piecewise polynomial approximation \eqref{eq:FVRec} does not
guarantee a continuous distribution on interfaces,
thus the numerical fluxes
$\Fn(\U_i,\U_j)$, $\Fn_v(\U_i,\U_j, \nabla \U_i, \nabla \U_j)$ are
functions of the approximate field on both sides. Inviscid numerical
flux $\Fn(\U_i,\U_j)$ is typically an approximate Riemann solver which
will be specified for each numerical test in the paper.
Numerical viscous flux $\Fn_v(\U_i,\U_j, \nabla \U_i, \nabla \U_j)$
in this paper follows the practice of Wang \cite{wang2017compact_VR}.

As the spacial derivatives are approximated in \eqref{eq:FVInt},
it is referred to as the semi-discretized form of finite volume method.
The inviscid term has a truncation error of $O(h^{p+1})$ for smooth problems,
with $h$ being the size of mesh. As the approximate fields $\U_i$ are functions
of average values $\UM_i$, \eqref{eq:FVInt} can be rearranged into the
assembled form
\begin{equation}
    \label{eq:FVODE}
    \frac{d\uu}{dt} = \R(t, \uu)
\end{equation}
with
\begin{equation}
    \uu = \begin{bmatrix}
        \UM_1 \\
        \dots \\
        \UM_{N_{cell}}
    \end{bmatrix},\ \
    \R = \begin{bmatrix}
        -\sum_{j\in S_1, j\neq 1}{\left(
            \int_{f_{1,j}}{
                [\Fn - \Fn_v] \cdot \n  dA
            }\right)
        }     \\
        \dots \\
        -\sum_{j\in S_{N_{cell}}, j\neq N_{cell}}{\left(
            \int_{f_{N_{cell},j}}{
                [\Fn - \Fn_v] \cdot \n  dA
            }\right)
        }
    \end{bmatrix}
\end{equation}
The arguments in the numerical fluxes are omitted.
The right-hand-side vector $\R$ is also a function of $t$
as boundary conditions or additional source terms
could depend on $t$ generally speaking.




\subsection{Variational Reconstruction}
\label{ssec:VR}

% TODO
\#\#\#


\section{Hermite Interpolation Implicit Runge Kutta Method}
\label{sec:HIRK}

\subsection{Time Marching Based on Interpolation}

The acquiring of an NIRK method with
certain order of accuracy is usually based on
a certain integration method and
corresponding taylor expansion analysis,
as described in \cite{kulikov2006familyNIRKOrig}.
However, the present paper proposes a single step method
derived with Hermite interpolation
(thus called HIRK),
which simplifies the acquiring of high
stage order and provides an approach to
modify the scheme's stability.

Considering the first order ODE arising from high-order finite volume method
with
$t\in[0,\infty)$ and $\uu\in \mathbb{R}^N$:
\begin{equation*}
    \frac{d\uu}{dt} = \R(t, \uu)
\end{equation*}
which is directly taken from equation \eqref{eq:FVODE}
With $\uu^n$ as the known numerical solution at $t=t^n$ and
$t^{n+1} = t^{n} + \inc t$,
we first consider the construction of implicit second order
time marching methods as an introduction.
First, form a linear interpolation for $t\in[t^n, t^{n+1}]$,
which gives an approximate time-distribution of
$\uu(t)=\frac{t^{n+1} - t}{\inc t}\uu^n + \frac{t - t^n}{\inc t}\uu^{n+1}$.
Second, use a second order accurate quadrature rule on
the linear time distribution. Evidently a trapezoid rule yields
trapezoid rule method or Crank-Nicolson method, and
midpoint rule yields the second order midpoint method.
Inspired by this procedure, now we proceed to construct
a high-order version.

For a single step implicit method,
if the implicitness is already solved,
the endpoint values $\uu^n, \uu^{n+1}$ are
given. Moreover,  $\R^n, \R^{n+1}$ can be
directly evaluated, where $\R^n = \R(t^n, \uu^n)$.
Given the endpoint values and corresponding first derivatives,
an Hermite interpolation can be given:
\newcommand{\ttt}{t^*}
\begin{equation}
    \label{eq:Hermite}
    \begin{aligned}
        \uu(t) & \approx (1-3{\ttt}^2 - 2 {\ttt}^3)\uu^n
        + (3{\ttt}^2 - 2 {\ttt}^3)\uu^{n+1}                    \\
               & + \inc t ({\ttt} - 2 {\ttt}^2 + {\ttt}^3) \R^n
        + \inc t (- {\ttt}^2 + {\ttt}^3) \R^{n+1}
    \end{aligned}
\end{equation}
where $\ttt = (t - t^n)/\inc t$ and $\ttt \in [0,1]$.
The Hermite interpolation \eqref{eq:Hermite}
has $O(\inc t^4)$ truncation error.
Next, a quadrature rule is applied. 
To utilize the endpoints and reduce memory requirement, 
we only insert one middle stage at $\ttt = c_2$. 
Using polynomial interpolation based 
numerical integration, with nodes $\ttt = 0,c_2,1$, 
the numerical integration of some function $r(t)$ would be
\begin{equation}
    \label{eq:Quad}
    \begin{aligned}
        \int_{t^n}^{t^{n+1}}r(t)dt & \approx \\
         \left(\frac{1}{2} - \frac{1}{6{c_2}}\right)r(t^n)
         &+
        \left(\frac{1}{6{c_2}(1-{c_2})}\right)r(t^n + c_2\inc t )
        +
        \left(\frac{1}{2} - \frac{1}{6(1-{c_2})}\right)r(t^{n+1})
    \end{aligned}
\end{equation}
using the relation $\int_{t^n}^{t^{n+1}}\R dt = \uu^{n+1} -\uu^{n}$,
there are two algebraic relations and two unknown vectors 
in total, which is able to form a solvable system.  
The quadrature rule \eqref{eq:Quad} has truncation error 
$O(\inc t^3)$ at least,
for it is based on second degree polynomial interpolation.


Summarizing the discussions above, the HIRK method has the form:
\begin{subequations}
    \label{eq:HM3}
    \begin{align}
        \uu^{n+1} & = \uu^{n} +
        \inc t
        \left[
            b_1\R(t^{n,1}, \uu^n) +
            b_2\R(t^{n,2}, \uu^*) +
            b_3\R(t^{n,3}, \uu^{n+1})
        \right]   \label{eq:HM3-1} \\
        \uu^{*}   & =
        a_1\uu^{n} +
        a_2\uu^{n+1} +
        \inc t
        \left[
            d_1\R(t^{n,1}, \uu^n) +
            d_2\R(t^{n,3}, \uu^{n+1})
            \right] \label{eq:HM3-2}
    \end{align}
\end{subequations}
where $t^{n,i}=t^n+c_i\inc t$, and $c_1 = 0, c_3 = 1, c_2\in(0,1)$.

The only stage value besides endpoints is $\uu^*$.
The internal stage $\uu^*$ can be explicitly
calculated with \eqref{eq:HM3-2}, which is derived
directly from the cubic Hermite interpolation of $\uu$
on interval $[t^n,t^{n+1}]$ evaluated at
$t^{n,2}$, which result in the interpolation relation:
\begin{equation}
    \begin{aligned}
        a_2 & = 1 - a_1 = 3{c_2}^2 - 2 {c_2}^3 \\
        d_1 & = {c_2} - 2 {c_2}^2 + {c_2}^3    \\
        d_2 & = - {c_2}^2 + {c_2}^3            \\
    \end{aligned}
    \label{eq:interp}
\end{equation}
The first equation \eqref{eq:HM3-1} is
a numeric integration on interval $[t^n,t^{n+1}]$ with
polynomial nodes
$t^{n,1}=t^n,t^{n,2}=t^n+c_2\inc t,t^{n,3}=t^{n+1}$, which demands:
\begin{equation}
    \begin{aligned}
        b_1 & = \frac{1}{2} - \frac{1}{6{c_2}}     \\
        b_2 & = \frac{1}{6{c_2}(1-{c_2})}          \\
        b_3 & = \frac{1}{2} - \frac{1}{6(1-{c_2})} \\
    \end{aligned}
    \label{eq:integ}
\end{equation}
The Hermite interpolation gives \eqref{eq:HM3-2}
local truncation error $O(\inc t^4)$,
and the numeric integration gives \eqref{eq:HM3-1}
local truncation error $O(\inc t^3)$, therefore the
classic order of accuracy of HIRK \eqref{eq:HM3} is
3. If $c_2=1/2$, then the numeric integration \eqref{eq:HM3-2}
becomes a Gauss-Lobatto quadrature rule, which yields
a local truncation error of $O(\inc t^4)$, making
the scheme 4th order accurate.
Also, from the interpolation, no matter
the choice of $c_2$, HIRK has a stage order of
3, making it stiffly accurate.



\subsection{Order of Accuracy}
To discuss the order of accuracy and stage order 
formally, HIRK can be considered as a standard IRK.
Reformulating \eqref{eq:HM3} into
a standard Runge-Kutta form yields a Butcher
tableau:
\begin{table}[htbp]
    \centering
    \begin{tabular}{c|ccc}
        0     & 0              & 0        & 0              \\
        $c_2$ & $d_1 + a_2b_1$ & $a_2b_2$ & $d_2 + a_2b_3$ \\
        1     & $b_1$          & $b_2$    & $b_3$          \\ \hline
              & $b_1$          & $b_2$    & $b_3$
    \end{tabular}
    \caption{Butcher tableau of \eqref{eq:HM3}}
    \label{tab:HM3Butcher}
\end{table}

From table \ref{tab:HM3Butcher} with the coefficients
decided with \eqref{eq:interp} and \eqref{eq:integ},
one can find that the 4th order accurate
HIRK $c_2=1/2$ method is indeed the Lobatto IIIA method
of order 4 \cite{wanner1996solving}.
The classic order and stage order of HIRK could
also be evaluated from table \ref{tab:HM3Butcher} via
the simplifying assumptions, which is a trivial procedure
given the formulae provided in \cite{wanner1996solving}.

If the quadrature rule in HIRK is
replaced with Gauss-Legendre rule,
the method immediately becomes a special case of the
Gauss type NIRK method of order 4
described in \cite{kulikov2006familyNIRKOrig}.
For large scale CFD application,
using 2 point Gauss-Legendre rule
would mean deriving the right hand side at
3 different stages iteratively.
Thus, the current HIRK method only considers
a 3 point Gauss-Lobatto type quadrature
(with the middle abscissa moved and order of accuracy reduced),
which would provide sufficient accuracy and only require 2 unknown stages.



% \begin{equation}
%     \label{eq:HM3R}
%     \begin{aligned}
%         \uu^{n+1} & = \uu^{n} +
%         \inc t
%         \left(
%         b_1\R(t^{n,1}, \uu^n) +
%         b_2\R(t^{n,2}, \uu^*) +
%         b_3\R(t^{n,3}, \uu^{n+1})
%         \right) \\
%         \uu^{*}   & =
%         \uu^{n}  + 
%         \inc t
%         \left(
%         (d_1 + a_2b_1)\R(t^{n,1}, \uu^n) +
%         a_2b_2\R(t^{n,2}, \uu^*) +
%         (d_2 + a_2b_3)\R(t^{n,3}, \uu^{n+1})
%         \right)
%     \end{aligned}
% \end{equation}

\subsection{Linear Stability}
\label{ssec:linStab}

Following standard analysis based on Dahlquist's equation
$\frac{dy}{dt} = \lambda y$ \cite{wanner1996solving},
the stability function giving $y^{1}=R(h\lambda)y^0$
when applying HIRK is in the form:
\begin{equation}
    \label{eq:stabilityFunc}
    R(z) = -\frac{4\,z-2\,c_{2}\,z-c_{2}\,z^2+z^2+6}{2\,z+2\,c_{2}\,z-c_{2}\,z^2-6}
\end{equation}
which becomes the (2,2)-Pad{\'e} approximation when $c_2=1/2$ and HIRK
becomes Lobatto IIIA. The limit
\begin{equation}
    \lim_{z\rightarrow\infty}R(z) = \frac{1-c_2}{c_2}
\end{equation}
gives that a necessary condition for $A$-stability of
HIRK is $c_2 \in [1/2,1)$, and shows that HIRK
is unable to achieve $L$-stability.
Further analysis on \eqref{eq:stabilityFunc}
would confirm $c_2 \in [1/2,1)$ is a sufficient
condition for $A$-stability.

HIRK($1/2$) or Lobatto IIIA method is symmetric,
which is a preferable property when integrating
reversible systems,
but the symmetry could be considered harmful in CFD application.
Most CFD systems of interest are physically dissipative,
while for symmetric RK methods
$R(z) \rightarrow 1$ when $z \rightarrow \infty$,
which is more likely to preserve
spurious modes arising from spacial discretization.
Although HIRK cannot achieve $L$-stability
by simply adjusting $c_2$,
using a non-trivial value $c_2 > 1/2$ would still
produce $\lim_{z\rightarrow\infty}R(z)\in(0,1)$, which
is a useful property in simulation of dissipative systems.
With  $c_2 > 1/2$, stiff modes could better vanish over the time
steps, while $c_2 = 1/2$ tends to preserve them.


\subsection{Solving Strategy}

\newcommand{\Res}{\mathcal{R}}
\newcommand{\Jres}{\mathcal{J}}
\newcommand{\eye}{\mathbf{I}}
\newcommand{\J}{\mathbf{J}}

HIRK's Butcher tableau in table \ref{tab:HM3Butcher}
indicates that apart from the first stage,
the other two stages seem fully coupled,
but following the original formulation
of HIRK \eqref{eq:HM3} which originates from
interpolation and integration,
clearly the internal stage $\uu^*$ can be explicitly
expressed by $\uu^n, \uu^{n+1}$ with the interpolation
relation \eqref{eq:HM3-2}, and one only need
to solve \eqref{eq:HM3-1} implicitly.
Therefore, the first solving strategy this paper
considers is identical to the spirit of NIRK,
which solves the equation:
\begin{equation}
    \label{eq:eqFull}
    \uu^{n+1} -
    \left(\uu^{n} + \inc t
    \left[
        b_1\R(t^{n,1}, \uu^n) +
        b_2\R(t^{n,2}, \uu^*) +
        b_3\R(t^{n,3}, \uu^{n+1})
        \right]
    \right)  =  0
\end{equation}
For simplicity, we denote the residual of \eqref{eq:eqFull}
as:
\begin{equation}
    \Res(\uu^{n+1}) \doteq \uu^{n+1} -
    \left(\uu^{n} + \inc t
    \left[
        b_1\R(t^{n,1}, \uu^{n}) +
        b_2\R(t^{n,2}, \uu^{*}) +
        b_3\R(t^{n,3}, \uu^{n+1})
        \right]
    \right)
\end{equation}
Considering $\uu^{n}$ is known,
and $\uu^{*}$ is explicitly expressed,
$\Res(\uu^{n+1})$ is considered only a
function of unknown $\uu^{n+1}$.
The Newton-Raphson method applied to
\eqref{eq:eqFull}'s solving would be
\begin{equation}
    \begin{aligned}
        \uu^{n+1,m+1}                  & =  \uu^{n+1,m} + \inc \uu^{n+1,m}, \\
        \frac{\partial \Res(\uu^{n+1,m})}
        {\uu^{n+1,m}} \inc \uu^{n+1,m} & = - \Res(\uu^{n+1,m})
    \end{aligned}
\end{equation}
and adding the pseudo time continuation
would be
\begin{equation}
    \label{eq:ntDtau}
    \begin{aligned}
        \uu^{n+1,m+1}            & =  \uu^{n+1,m} + \inc \uu^{n+1,m}, \\
        \left(
        \frac{\partial \Res(\uu^{n+1,m})}
        {\uu^{n+1,m}} + \inc t \Tau^{-1}
        \right) \inc \uu^{n+1,m} & = - \Res(\uu^{n+1,m})
    \end{aligned}
\end{equation}
where $\Tau=\mathrm{diag}(\tau_1,...\tau_N)$ is a diagonal matrix with
local pseudo time steps as its diagonal values.
The pseudo time continuation of Newton iteration
could be both understood as a relaxation of original
method for nonlinear stability,
or as the result of solving dual time stepping
method Jameson developed \cite{jameson1991time}.
In other words, \eqref{eq:ntDtau} is the result
of solving pseudo time evolution
$\frac{d\uu^{n+1}}{d\tau} = -\frac{\Res}{\inc t}$
with linearly implicit backward Euler method and
a local time stepping.
Such dual time stepping is prevalent in transient
flow solution due to the nonlinearity in
fluid systems.
However, pseudo time term could
cause trouble if we try to solve HIRK
of any MIRK type system with certain approaches, which
will be illustrated later.

The expanded form of residual's Jacobian
is
\begin{equation}
    \label{eq:fullJCB}
    \begin{aligned}
        \frac{\partial \Res(\uu^{n+1})}
        {\uu^{n+1}}
                     & = \eye - \inc t b_3 \J^{n+1} -
        \inc t b_2\J^*(a_2\eye +\inc t d_2 \J^{n+1})                                \\
                     & = \frac{d_2 + a_2b_3}{d_2}\eye
        -\frac{a_2b_3}{d_2}\left(
        \eye + \frac{d_2b_2}{b_3}\inc t\J^*
        \right)\left(
        \eye + \frac{d_2}{a_2}\inc t\J^{n+1}
        \right)                                                                     \\
        \text{with:} &                                                              \\
                     & \J^* = \frac{\partial \R(t^{n,2},\uu^*)}{\partial \uu^*},\ \
        \J^{n+1} = \frac{\partial \R(t^{n,3},\uu^{n+1})}{\partial \uu^{n+1}}
    \end{aligned}
\end{equation}
which is a quadratic polynomial of right-hand-sides'
Jacobian.
If the Jacobian matrices could be explicitly formed and
manipulated, solving \eqref{eq:ntDtau} would be straightforward.
But a lot of high order methods rely on matrix-free
Jacobian evaluation, thus solving the linear system
with its matrix in the form of \eqref{eq:fullJCB}
would be troublesome or impossible.
Even if one would like to use a matrix-less linear solver
like Krylov space solvers,
powerful matrix-free preconditioners like ILU(0) or
LUSGS would be unavailable.

The solution to the complexity of Jacobian
by Kulikov and Shindin
is using an approximate factorization
\cite{kulikov2006familyNIRKOrig,kulikov2009adaptive}.
For the forth order
Gauss type NIRK in \cite{kulikov2006familyNIRKOrig},
Kulikov and Shindin used $(\eye-\inc t /4 \J)^2$
as an approximation.
This paper considers the form
\begin{equation}
    \label{eq:factJCB}
    \begin{aligned}
        \frac{\partial \Res(\uu^{n+1})}
        {\uu^{n+1}}
         & \approx
        -\frac{a_2b_3}{d_2}\left(
        \eye + \frac{d_2b_2}{b_3}\inc t\J^*
        \right)\left(
        \eye + \frac{d_2}{a_2}\inc t\J^{n+1}
        \right)    \\
    \end{aligned}
\end{equation}
which is directly taken from the last term
in \eqref{eq:fullJCB}, and the omitted term
is identity matrix with coefficient $\frac{d_2 + a_2b_3}{d_2}>0$
for $c_2\in(0,1)$. Note that $d_2<0$ for any possible $c_2$.

Using a factorized form of approximate
Jacobian like \eqref{eq:factJCB} enables the use of
two successive matrix-free solvers to obtain
the increment for Newton iteration.

For practical CFD implementation,
pseudo time term is now considered.
In order to preserve the factorized form,
this paper finds using
\begin{equation}
    \label{eq:ntDtau_Fact}
    \begin{aligned}
        \uu^{n+1,m+1}    & =  \uu^{n+1,m} + \inc \uu^{n+1,m}, \\
        -\frac{a_2b_3}{d_2}\left(
        \eye + \frac{d_2b_2}{b_3}\inc t\J^*
        + \inc t \Tau^{-1}
        \right)\left(
        \eye + \frac{d_2}{a_2}\inc t\J^{n+1}
        \right)
        \inc \uu^{n+1,m} & = - \Res(\uu^{n+1,m})
    \end{aligned}
\end{equation}
as the pseudo time continued Newton iteration
satisfactory.
In the linear sense, using this this approximate
Jacobian and pseudo time stepping does not sabotage
the convergence of Newton iteration, which can
be shown by applying the iteration \eqref{eq:ntDtau_Fact}
to solving scalar ODE $\frac{dy}{dt} = \lambda y$.
For multi-dimensional linear ODEs, using a Jordan decomposition
would make the proof reduce to scalar equation. \#\#\#\#


% Due to the explicit nature of the internal 
% stage $\uu^*$, when solving nonlinear systems,
% the un-converged state of $\uu^{n+1}$ at 
% the beginning of iteration could put $\uu^*$
% far from the real solution, 
% causing the right-hand-side to behave bad
% and possibly make the iteration breakdown. 
% Therefore, this paper presents another approach of solving 
% HIRK step which is vital for nonlinear ODEs.

% In order to account for nonlinearity, 
% we forsake the explicit nature in the 
% determination of $\uu^*$ as described in \eqref{eq:HM3-2}, 
% which is an Hermite interpolation linear dependent 
% on $\uu^{n},\uu^{n+1},\R^n, \R^{n+1}$.

This paper also provides another kind of
solving strategy,
which forsakes the explicitness in \eqref{eq:HM3-2},
thus making $\uu^*$ the dof to be solved,
which is the case for a general IRK scheme.
The equation to solve would be:
\begin{equation}
    \begin{aligned}
                                  & \left\{
        \begin{array}[2]{ll}
            \Res(\uu^{n+1},\uu^{*})   & = 0 \\
            \Res^*(\uu^{n+1},\uu^{*}) & = 0 \\
        \end{array}
        \right.                                               \\
    \end{aligned}
\end{equation}
with
\begin{equation}
    \begin{aligned}
        \Res(\uu^{n+1},\uu^{*})   & \doteq \uu^{n+1} - \left(
        \uu^{n} +
        \inc t
        \left[
            b_1\R(t^{n,1}, \uu^n) +
            b_2\R(t^{n,2}, \uu^*) +
            b_3\R(t^{n,3}, \uu^{n+1})
            \right]
        \right)                                               \\
        \Res^*(\uu^{n+1},\uu^{*}) & \doteq\uu^{*} - \left(
        a_1\uu^{n} +
        a_2\uu^{n+1} +
        \inc t
        \left[
            d_1\R(t^{n,1}, \uu^n) +
            d_2\R(t^{n,3}, \uu^{n+1})
            \right]
        \right)
    \end{aligned}
\end{equation}
Making $\uu^*$ unknown has two major drawbacks.
The first drawback is that additional memory
would be required for $\uu^*$'s storage.
Considering HIRK saves much space compared to
DIRK methods, and HIRK also requires some more space
for intermediate results even using explicit $\uu^*$ evaluation,
the first drawback would not be significant.
The second drawback is the increase in the dimension of
algebraic system.
Normally, the enlarged system can be solved
using appropriate blocking strategy,
for example in \cite{pazner2017stage}.
However, the current scheme takes a different form of
iteration which takes two sub-steps:
\begin{equation}
    \label{eq:intersolve}
    \begin{aligned}
        \uu^{*,m+1}   & = \uu^{*,m} - \left[
            \eye - \inc t \frac{\partial \Res^{*'}(\uu^{n+1,m},\uu^{*,m})}
            {\partial \uu^{*,m}}
            + \inc t \Tau^{-1}
            \right]
        \backslash \Res^{*'}(\uu^{n+1,m},\uu^{*,m}) \\
        \uu^{n+1,m+1} & = \uu^{n+1,m} - \left[
            \eye - \inc t \frac{\partial \Res^{}(\uu^{n+1,m},\uu^{*,m+1})}
            {\partial \uu^{n+1,m}}
            + \inc t \Tau^{-1}
            \right]
        \backslash \Res^{}(\uu^{n+1,m},\uu^{*,m+1}) \\
    \end{aligned}
\end{equation}
where the $\mathbf{A}\backslash \mathbf{b}$
notation means to solve the linear problem $\mathbf{A}\mathbf{x}=\mathbf{b}$ once.
The residual $\Res^{*'}$ is defined with:
\begin{equation}
    \Res^{*'}(\uu^{n+1},\uu^{*}) = \Res^*(\uu^{n+1},\uu^{*}) + \beta\Res(\uu^{n+1},\uu^{*})
\end{equation}
which serves as the residual preconditioned with transformation
\begin{equation*}
    \begin{bmatrix}
        \Res^{} \\
        \Res^{*'}
    \end{bmatrix} =
    \begin{bmatrix}
        \eye & 0 \\ \beta\eye & \eye
    \end{bmatrix}
    \begin{bmatrix}
        \Res^{} \\
        \Res^{*}
    \end{bmatrix}
\end{equation*}
with $\beta\in\mathbb{R}$.
In \cite{jameson2017evaluation} Jameson used the inverse of Butcher coefficients
for preconditioning, which makes off-diagonal blocks of
the Jacobian scalar.
That preconditioning could
be adopted in the current method,
but is not recommended for
possible instabilities in the presence of negative pressure fixing in
numeric tests. \#\#\#\#

The solving procedure \eqref{eq:intersolve} could be regarded as
successively updating $\uu^*$ with $\Res^{*'}$ and $\uu$
with $\Res^{}$, by using the latest values of the other DOF.
Within a linear context,
this would be a blocks Gauss-Seidel iteration
over the $2\times2$ blocks of system with each block being $N\times N$.
In other words,to solve:
\begin{equation*}
    \begin{bmatrix}
        \Res^{}(\uu^{n+1},\uu^{*}) \\
        \Res^{*'}(\uu^{n+1},\uu^{*})
    \end{bmatrix} = 0
\end{equation*}
the canonical quasi Newton iteration would need to solve
\begin{equation}
    \label{eq:fullCoupled}
    \begin{bmatrix}
        \frac{\partial\Res^{}(\uu^{n+1,m},\uu^{*,m})}{\partial\uu^{n+1,m}} + \inc t\Tau^{-1} &
        \frac{\partial\Res^{}(\uu^{n+1,m},\uu^{*,m})}{\partial\uu^{*,m}}                       \\
        \frac{\partial\Res^{*'}(\uu^{n+1,m},\uu^{*,m})}{\partial\uu^{n+1,m}}                 &
        \frac{\partial\Res^{*'}(\uu^{n+1,m},\uu^{*,m})}{\partial\uu^{*,m}} + \inc t\Tau^{-1}   \\
    \end{bmatrix}
    \begin{bmatrix}
        \inc\uu^{n+1,m} \\
        \inc\uu^{*,m}
    \end{bmatrix}
    =
    -\begin{bmatrix}
        \Res^{}(\uu^{n+1,m},\uu^{*,m}) \\
        \Res^{*'}(\uu^{n+1,m},\uu^{*,m})
    \end{bmatrix}
\end{equation}
to update both stage values concurrently.
The current method \eqref{eq:intersolve}
first solve the second block row of
\eqref{eq:fullCoupled} for the increment of $\uu^*$,
then solve the first block row
for the increment of $\uu^{n+1}$ using updated $\uu^*$.
The current solving strategy will
be referred to as successive solving in the following parts.

The omitting of off-diagonal relations in \eqref{eq:fullCoupled},
or the block nonlinear Gauss-Seidel handling on the top layer of
algorithm brings about extra error in iteration,
causing slow-down of iteration and possible divergence.
To analyze such behavior, the current research investigates
the impact of successive solving \eqref{eq:intersolve}
brought to solution of HIRK applied to linear problems
using precise linear solvers.
With a traditional quasi Newton iteration,
if pseudo time steps approaches infinity,
the iteration would converge in the first step in such
situation.
The introduction of successive solving \eqref{eq:intersolve}
renders this one-step-convergence impossible, thus
the convergence with successive solving will represent
all the deceleration effect caused by it.
The linear situation discussed could also be a linearization
of a non-linear ODE when the stage values converge near the
solution, and the instant convergence of Newton iteration would
be first order accurate.
In the linear or linearized scene,
the residual takes the form:
\begin{equation}
    \label{eq:linearized}
    \begin{aligned}
        \Res^{}(\uu^{n+1},\uu^{*})   & =
        \Res^{}_0 - \inc t b_2\J^*\uu^{*} + (\eye - \inc t b_3\J)\uu^{n+1} \\
        \Res^{*'}(\uu^{n+1},\uu^{*}) & =
        \Res^{*'}_0 + (\eye - \beta\inc t b_2\J^*)\uu^{*}
        + ((\beta-a_2)\eye - \inc t (\beta b_3 - d_2)\J)\uu^{n+1}
    \end{aligned}
\end{equation}
where $\J^*, \J$ are Jacobian of $\R$
at the solution of
$\uu^{*}, \uu^{n+1}$.
Applying \eqref{eq:intersolve} to
this linear form and assuming a infinite pseudo
time step,
following textbook analysis conducted on
Gauss-Seidel iteration,
the successive solving becomes a linear
fixed point iteration, with fixed point
mapping's matrix being
\begin{equation}
    \mathbf{B}_{SS}=\begin{bmatrix}
        \eye - \beta\inc t b_2\J^* & 0                   \\
        - \inc t b_2\J^*           & \eye - \inc t b_3\J \\
    \end{bmatrix}^{-1}
    \begin{bmatrix}
        0 & (\beta-a_2)\eye - \inc t (\beta b_3 - d_2)\J \\
        0 & 0                                            \\
    \end{bmatrix}
\end{equation}
Thus, convergence of the fixed point iteration equals to
the condition
\begin{equation}
    \label{eq:rhoGS}
    \begin{aligned}
         & \varUpsilon(\mathbf{B}_{SS}) \\
         & =\varUpsilon\left(
        -[\eye - \inc t b_3\J]^{-1}
        [- \inc t b_2\J^*]
        [\eye - \beta\inc t b_2\J^*]^{-1}
        [(\beta-a_2)\eye - \inc t (\beta b_3 - d_2)\J]
        \right)                         \\
         & < 1
    \end{aligned}
\end{equation}
where $\varUpsilon$ is spectral radius of matrix.
For arbitrary $\J,\J^*$, further analysis is difficult,
so we limit the situation to where $\J = \J^*$ is an acceptable
approximation, or the ODE is linear itself.
Using the Jordan form,
and assuming all the inverse are existent and precisely solved,
\eqref{eq:rhoGS} would become
\begin{equation}
    \label{eq:rhoGS1}
    \begin{aligned}
        \varrho_i =
        \left|
        -[1 -  b_3z_i]^{-1}
        [- b_2z_i]
        [1 - \beta b_2z_i]^{-1}
        [(\beta-a_2) - (\beta b_3 - d_2)z_i]
        \right| & < 1,\ \ \forall z_i = \inc t \lambda_i
    \end{aligned}
\end{equation}
where $\lambda_i$ is eigenvalues of $\J$.
By further assuming $\mathfrak{Re} z_i < 0$
which is true for stable semi-discretized
method used on bounded linear problems,
special cases were analyzed.
For $c_2=0.5, \beta=0.5$, it is found
$\varrho_i < 0.5$.
For $c_2=0.5, \beta=1$, it is found $\varrho_i < 0.42$.
For $c_2=0.55, \beta=0.5$, $\varrho_i$ could exceed 1.
For $c_2=0.55, \beta=1$, it is found $\varrho_i < 0.36$.
These analyses are trivial which involve finding maximal points
in the left complex plane and on the imaginary axis.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=3in]{pics/numSearchRho.png}
    \caption{Numerical search result }
    \label{fig:numSearchRho}
\end{figure}

Numerical search is conducted to find
\begin{equation}
    \varrho_m(\beta) = \max_{\forall i}(\varrho_i)
\end{equation}
whose result is shown in figure \ref{fig:numSearchRho}.
Figure \ref{fig:numSearchRho} indicates
at least for $c_2\in[0.5,0.6]$, $\varrho_m<1$
could be satisfied easily by adjusting $\beta$, therefore
achieving convergence in Gauss-Seidel iteration.
For optimal Gauss-Seidel convergence rate,
values of $\beta$ could be found by numeric searching
as shown in figure \ref{fig:numSearchRho}.
Figure \ref{fig:numSearchRho} also suggests
$c_2=0.5$ helps acquiring better convergence rage
in successive solving.

The current successive solving approach
differs from previous ones,
which only requires linear solutions of
the same dimension as the ODE.
This property makes HIRK's implementation
very similar to traditional DIRK or BDF methods,
thus taking less effort.





\section{Numerical Tests}

During numerical tests,
BDF2 and ESDIRK4 methods taken from
\cite{bijl2002implicitBDFvESDIRK,kennedy2003additiveARK}
are chosen to be
baseline time marching methods.
For HIRK method, instances of
$c_2 = 0.5$ and $c_2 = 0.55$ are tested.
For $c_2 = 0.5$, the method is 4th order accurate and
is essentially the Lobatto IIIA method \cite{wanner1996solving}.
For $c_2 = 0.55$ which has 3rd order accuracy,
the symmetry is broken and linear stability is
improved as clarified in \ref{ssec:linStab}.
Both HIRK methods employ successive
solving in the form of \eqref{eq:intersolve},
with $\beta$ chosen as empirical values $1,4/3$ respectively.


The isentropic vortex, two dimensional vortex shedding
and  double mach reflection problems use
$P^3$ variational reconstruction finite volume method declared in
section \ref{sec:CFV} as spacial discretization.
Iterative solution of the implicit reconstruction
is conducted before each right-hand-side evaluation,
which consists of 1 block-Jacobi iteration by default.
Pseudo time continued Newton iteration on mean values are
solved using 5 times of block-Jacobi iteration by default,
which is found both stable and efficient enough for VFV solving
transient problems.
It should be noted that, in other words,
both the reconstruction system and
the time stepping implicit system use linear solvers that
runs for a fixed number of steps without monitoring convergence.
Only the magnitude of the nonlinear time stepping residual
is monitored to ensure convergence.
This linear solving method simplifies the control flow of
the program,
while providing a simple yet reliable way of
comparing total calculation consumption between ODE solvers,
which will be explained in section \ref{ssec:resultIV}.



\subsection{Isentropic Vortex}
\label{ssec:resultIV}

The isentropic vortex problem is a classic
accuracy testing problem for Euler equations.
The settings can be found in \cite{hu1999weighted_WENO}.
The free-stream flow is $(\rho,u,v,p)=(1,1,1,1)$,
and a perturbation at initial time:
\begin{equation}
    \left\{
    \begin{array}[2]{ll}
        (\delta u, \delta v) & = \frac{\epsilon}{2\pi}\exp(\frac{1-[(x-x_c)^2+(y-y_c)^2]}{2})(-y+y_c,x-x_c) \\
        \delta T             & = - \frac{(\gamma-1)\epsilon^2}{8\gamma\pi^2}\exp(1-[(x-x_c)^2+(y-y_c)^2])   \\
        \delta S             & = 0                                                                          \\
    \end{array}
    \right.
\end{equation}
with ideal gas setting of $T = p/\rho, S= p/\rho^\gamma, \gamma =1.4$.
Initial vortex center is chosen $(x_c,y_c)=(5,5)$, 
and vortex strength is $\epsilon = 5$.
The analytic solution to the isentropic vortex problem is a
translation of initial field with speed $(1,1)$.
The computational domain is $[0,10]\times[0,10]$,
using periodic boundary conditions.

First, the implicit ODE integrators are tested with large
time steps.
The mesh is $40\times40$ square grid,
and solution is calculated until $t=10$ with $\inc t=1$.
The CFL number based on $\inc t, \inc x$ is roughly $11$,
making the propagation of the vortex hard to
simulate.

\begin{figure}[htbp]
    \centering
    \begin{subfigure}{0.5\textwidth}
        \includegraphics[width=\textwidth]{pics/IV40_10steps_HM3LBT.png}
        \caption[]{HIRK $c_2=0.5$}
        \label{sfig:IV10Step_HM3LBT}
    \end{subfigure}\hfill
    \begin{subfigure}{0.5\textwidth}
        \includegraphics[width=\textwidth]{pics/IV40_10steps_HM3.png}
        \caption[]{HIRK $c_2=0.55$}
        \label{sfig:IV10Step_HM3}
    \end{subfigure}\\
    \begin{subfigure}{0.5\textwidth}
        \includegraphics[width=\textwidth]{pics/IV40_10steps_ESDIRK4.png}
        \caption[]{ESDIRK4}
        \label{sfig:IV10Step_ESDIRK4}
    \end{subfigure}\hfill
    \begin{subfigure}{0.5\textwidth}
        \includegraphics[width=\textwidth]{pics/IV40_10steps_BDF2.png}
        \caption[]{BDF2}
        \label{sfig:IV10Step_BDF2}
    \end{subfigure}
    \caption{Density distribution of isentropic vortex problem, with $\inc t = 1$ at $t=10$}
    \label{fig:IV10Step}
\end{figure}

Results of large time step testing are shown in figure \ref{fig:IV10Step}.
Clearly, from figure \ref{sfig:IV10Step_BDF2}, BDF2 almost completely
smears the initial vortex with only 10 steps for one period.
The higher order methods somehow preserves the characteristics of
a vortex. HIRK $c_2=0.5$ produces significant numerical oscillation along
the propagation direction as shown in figure \ref{sfig:IV10Step_HM3LBT},
while the $c_2=0.55$ HIRK inhibits them better in figure \ref{sfig:IV10Step_HM3}.
The peak value in the vortex center produced by HIRK $c_2=0.5$ is comparable with
ESDIRK4, while HIRK $c_2=0.55$ gives a flatter density peak.

Next, precision and efficiency of different ODE methods are
qualitatively evaluated with isentropic vortex solved on a $160\times160$
grid until $t=2$.
The fine mesh makes spacial error negligible compared with 
temporal error.
The density error is defined as
\begin{equation}
    \epsilon_\rho = \frac{\int_{(x,y)\in[4,9]\times[4,9]}{|\rho-\rho_a dxdy}|}{
    |[4,9]\times[4,9]|
    }
\end{equation}
with $[4,9]\times[4,9]=25$ the area of evaluating region, $\rho$ the numeric result
and $\rho_a$ the analytic result.
The evaluating region is limited to $[4,9]\times[4,9]=25$ 
where the vortex center 
and most numerical error resides. 



\begin{figure}[htbp]
    \centering
    \begin{subfigure}{0.5\textwidth}
        \includegraphics[width=\textwidth]{pics/HM3_IV160_fig_1.png}
        \caption[]{Density error vs. time step size }
        \label{sfig:IVTests_Conv}
    \end{subfigure}\hfill
    \begin{subfigure}{0.5\textwidth}
        \includegraphics[width=\textwidth]{pics/HM3_IV160_fig_2.png}
        \caption[]{Density error vs. total CPU time consumption}
        \label{sfig:IVTests_Eff}
    \end{subfigure}
    \caption[]{Convergence and efficiency test with isentropic vortex problem}
    \label{fig:IVTests}
\end{figure}

Results of convergence and efficiency study with isentropic vortex is 
shown in figure \ref{fig:IVTests}. 
Figure \ref{sfig:IVTests_Conv} indicates that all the ODE methods 
could roughly achieve their theoretical order of accuracy.
With the same time step size, figure \ref{sfig:IVTests_Conv} shows 
ESDIRK4 has best accuracy, while HIRK $c_2=0.5$ is close to 
ESDIRK4 when time step is refined. HIRK $c_2=0.55$ is less accurate 
than HIRK $c_2=0.5$, but it performs almost as well as 
HIRK $c_2=0.5$ when time step is large. 
Figure \ref{sfig:IVTests_Eff}
implies that when consuming the same computational resource,
HIRK methods have best accuracy or efficiency. All the high order 
time marching methods have better efficiency than BDF2, 
while HIRK methods have better efficiency than ESDIRK4. 
The symmetric HIRK $c_2=0.5$ has better efficiency 
compared with more stable HIRK $c_2=0.55$.

The convergence and efficiency study with isentropic vortex was 
conducted on a isolated server with 2 Intel Xeon 6326 processors with 
16 cores each, with measures to ensure the stability of CPU time measurement.
Further tests with vortex shedding and double mach reflection 
were conducted on a large cluster, which unfortunately produces more
unstable CPU time due to disturbances of the communication network.
Therefore, following numerical tests will use the effective iterations 
to represent total computational consumption.
Due to the settings of the current research, each updating in 
the implicit solving consumes almost identical time.
For BDF2, each right-hand-side evaluation, linear solving and updating 
is counted as $1.0$ effective iteration. 
For ESDIRK4, as each updating of some stage value is quite similar with 
BDF2 apart from some extra linear summations, each updating is also 
counted as $1.0$ effective consumption. 
For HIRK methods, each updating of $\uu^*,\uu^{n+1}$ 
involves two right-hand-side evaluations and linear solver executions.
Therefore, each HIRK updating is counted as $2.0$ effective iterations.
Although one could calibrate the coefficients using theoretical analyses or 
empirical data to get a more precise measurement of consumption, 
the current simple coefficients for effective iterations are found to 
be sufficient.

\begin{figure}[htbp]
    \centering
    \begin{subfigure}{0.5\textwidth}
        \includegraphics[width=\textwidth]{pics/HM3_IV160_fig_21.pdf}
        \caption[]{Density error vs. effective iterations }
        \label{sfig:IVTests2_EffIt}
    \end{subfigure}\hfill
    \begin{subfigure}{0.5\textwidth}
        \includegraphics[width=\textwidth]{pics/HM3_IV160_fig_4.pdf}
        \caption[]{CPU time vs. effective iterations}
        \label{sfig:IVTests2_CPUVEffIt}
    \end{subfigure}
    \caption[]{The impact of using iteration counting to measure total work}
    \label{fig:IVTests2}
\end{figure}

Figure \ref{fig:IVTests2} illustrates the impact of using effective iteration
as total computational work. Qualitatively, figure \ref{sfig:IVTests2_EffIt}
is identical to figure \ref{sfig:IVTests_Eff}, 
and figure  \ref{sfig:IVTests2_CPUVEffIt} shows strong linear correlation 
between CPU time and effective iterations with their 
$log_{10}$ values having correlation coefficient $r=0.9943$. 
Therefore, the cases of isentropic vortex which are conducted in 
a stable environment indicate that the effective iteration is 
a reliable measurement of computational consumption.

\subsection{Two Dimensional Vortex Shedding}

Vortex shedding from a circular cylinder and forming a vortex street
is a classic test problem for transient fluid simulation. Due to the refined 
mesh near solid wall, such cases usually prefer implicit time marching
over explicit ones whose time steps are bounded by CFL condition.
The current paper studies the 2D laminar case, where
Reynolds number 
$Re_d=\rho_\infty u_\infty d / \mu_\infty $ is around $10^3$, 
with Mach number $Ma=0.1$ which makes the flow almost incompressible.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.7\textwidth]{pics/CylinderA1_Re2000_Mesh.png}
    \caption[]{Part of mesh used in $Re=2000$ vortex shedding problem}
    \label{fig:CylinderRe2000_Mesh}
\end{figure}

\begin{figure}[htbp]
    \centering
    \begin{subfigure}{0.5\textwidth}
        \includegraphics[width=\textwidth]{pics/CylinderA1_Re2000_HM3LBT.png}
        \caption[]{HIRK $c_2=0.5$}
        \label{sfig:CylinderRe2000_HM3LBT}
    \end{subfigure}\hfill
    \begin{subfigure}{0.5\textwidth}
        \includegraphics[width=\textwidth]{pics/CylinderA1_Re2000_HM3.png}
        \caption[]{HIRK $c_2=0.55$}
        \label{sfig:CylinderRe2000_HM3}
    \end{subfigure}
    \caption[]{Comparison of pressure distribution in $Re=2000$ vortex shedding problem}
    \label{fig:CylinderRe2000}
\end{figure}

\begin{figure}[htbp]
    \centering
    \begin{subfigure}{0.5\textwidth}
        \includegraphics[width=\textwidth]{pics/CylinderB1_Re1200_Mesh.png}
        \caption[]{Mesh}
        \label{sfig:CylinderRe1200Demo_Mesh}
    \end{subfigure}\hfill
    \begin{subfigure}{0.5\textwidth}
        \includegraphics[width=\textwidth]{pics/CylinderB1_Re1200.png}
        \caption[]{Vorticity distribution}
        \label{sfig:CylinderRe1200Demo_Vort}
    \end{subfigure}
    \caption[]{Mesh and a instance of z-vorticity distribution
        in $Re=1200$ vortex shedding problem}
    \label{fig:CylinderRe1200Demo}
\end{figure}



\begin{figure}[htbp]
    \centering
    \begin{subfigure}{0.5\textwidth}
        \includegraphics[width=\textwidth]{pics/Cylinder_fig14.pdf}
        \caption[]{Error vs. time step size}
        \label{sfig:CylinderRe1200_My_C}
    \end{subfigure}\hfill
    \begin{subfigure}{0.5\textwidth}
        \includegraphics[width=\textwidth]{pics/Cylinder_fig4.pdf}
        \caption[]{Error vs. effective iterations}
        \label{sfig:CylinderRe1200_My_E}
    \end{subfigure}
    \caption[]{Convergence and efficiency analysis with $\epsilon_{My}$ in $Re=1200$ vortex shedding problem}
    \label{fig:CylinderRe1200_My}
\end{figure}

\begin{figure}[htbp]
    \centering
    \begin{subfigure}{0.5\textwidth}
        \includegraphics[width=\textwidth]{pics/Cylinder_fig15.pdf}
        \caption[]{Error vs. time step size}
        \label{sfig:CylinderRe1200_Mx_C}
    \end{subfigure}\hfill
    \begin{subfigure}{0.5\textwidth}
        \includegraphics[width=\textwidth]{pics/Cylinder_fig5.pdf}
        \caption[]{Error vs. effective iterations}
        \label{sfig:CylinderRe1200_Mx_E}
    \end{subfigure}
    \caption[]{Convergence and efficiency analysis with $\epsilon_{Mx}$ in $Re=1200$ vortex shedding problem}
    \label{fig:CylinderRe1200_Mx}
\end{figure}

\begin{figure}[htbp]
    \centering
    \begin{subfigure}{0.5\textwidth}
        \includegraphics[width=\textwidth]{pics/Cylinder_fig13.pdf}
        \caption[]{Error vs. time step size}
        \label{sfig:CylinderRe1200_St_C}
    \end{subfigure}\hfill
    \begin{subfigure}{0.5\textwidth}
        \includegraphics[width=\textwidth]{pics/Cylinder_fig3.pdf}
        \caption[]{Error vs. effective iterations}
        \label{sfig:CylinderRe1200_St_E}
    \end{subfigure}
    \caption[]{Convergence and efficiency analysis with $\epsilon_{St}$ in $Re=1200$ vortex shedding problem}
    \label{fig:CylinderRe1200_St}
\end{figure}




\subsection{Double Mach Reflection}

\begin{figure}[htbp]
    \centering
    \begin{subfigure}{0.5\textwidth}
        \includegraphics[width=\textwidth]{pics/DM480_HM3LBT.png}
        \caption[]{HIRK $c_2=0.5$}
        \label{sfig:DM480_HM3LBT}
    \end{subfigure}\hfill
    \begin{subfigure}{0.5\textwidth}
        \includegraphics[width=\textwidth]{pics/DM480_HM3.png}
        \caption[]{HIRK $c_2=0.55$}
        \label{sfig:DM480_HM3}
    \end{subfigure}\\
    \begin{subfigure}{0.5\textwidth}
        \includegraphics[width=\textwidth]{pics/DM480_ESDIRK.png}
        \caption[]{ESDIRK4}
        \label{sfig:DM480_ESDIRK4}
    \end{subfigure}\hfill
    \begin{subfigure}{0.5\textwidth}
        \includegraphics[width=\textwidth]{pics/DM480_BDF.png}
        \caption[]{BDF2}
        \label{sfig:DM480_BDF2}
    \end{subfigure}
    \caption{Density distribution in double mach reflection problem}
    \label{fig:DM480}
\end{figure}

\section{Conclusion}


%% The Appendices part is started with the command \appendix;
%% appendix sections are then done as normal sections
%% \appendix

%% \section{}
%% \label{}

%% If you have bibdatabase file and want bibtex to generate the
%% bibitems, please use
%%
\bibliographystyle{elsarticle-num}
\bibliography{HM3DraftRefs.bib}

%% else use the following coding to input the bibitems directly in the
%% TeX file.

% \begin{thebibliography}{00}

%     %% \bibitem{label}
%     %% Text of bibliographic item

%     \bibitem{}

% \end{thebibliography}


\end{document}
\endinput
%%
%% End of file `elsarticle-template-num.tex'.
