%% 
%% Copyright 2007-2020 Elsevier Ltd
%% 
%% This file is part of the 'Elsarticle Bundle'.
%% ---------------------------------------------
%% 
%% It may be distributed under the conditions of the LaTeX Project Public
%% License, either version 1.2 of this license or (at your option) any
%% later version.  The latest version of this license is in
%%    http://www.latex-project.org/lppl.txt
%% and version 1.2 or later is part of all distributions of LaTeX
%% version 1999/12/01 or later.
%% 
%% The list of all files belonging to the 'Elsarticle Bundle' is
%% given in the file `manifest.txt'.
%% 

%% Template article for Elsevier's document class `elsarticle'
%% with numbered style bibliographic references
%% SP 2008/03/01
%%
%% 
%%
%% $Id: elsarticle-template-num.tex 190 2020-11-23 11:12:32Z rishi $
%%
%%
\documentclass[preprint,12pt]{elsarticle}

%% Use the option review to obtain double line spacing
%% \documentclass[authoryear,preprint,review,12pt]{elsarticle}

%% Use the options 1p,twocolumn; 3p; 3p,twocolumn; 5p; or 5p,twocolumn
%% for a journal layout:
%% \documentclass[final,1p,times]{elsarticle}
%% \documentclass[final,1p,times,twocolumn]{elsarticle}
%% \documentclass[final,3p,times]{elsarticle}
%% \documentclass[final,3p,times,twocolumn]{elsarticle}
%% \documentclass[final,5p,times]{elsarticle}
%% \documentclass[final,5p,times,twocolumn]{elsarticle}

%% For including figures, graphicx.sty has been loaded in
%% elsarticle.cls. If you prefer to use the old commands
%% please give \usepackage{epsfig}

%% The amssymb package provides various useful mathematical symbols
\usepackage{amssymb}
\usepackage{amsmath}
%% The amsthm package provides extended theorem environments
%% \usepackage{amsthm}

%% The lineno packages adds line numbers. Start line numbering with
%% \begin{linenumbers}, end it with \end{linenumbers}. Or switch it on
%% for the whole article with \linenumbers.
%% \usepackage{lineno}

\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
    }
\usepackage{subcaption}

\journal{Journal's Name}

\begin{document}

\begin{frontmatter}

    %% Title, authors and addresses

    %% use the tnoteref command within \title for footnotes;
    %% use the tnotetext command for theassociated footnote;
    %% use the fnref command within \author or \address for footnotes;
    %% use the fntext command for theassociated footnote;
    %% use the corref command within \author for corresponding author footnotes;
    %% use the cortext command for theassociated footnote;
    %% use the ead command for the email address,
    %% and the form \ead[url] for the home page:
    \title{An Efficient Implicit Runge-Kutta Method
        Based on Time Interpolation
        for High-order Finite Volume Method}
    % \tnotetext[label1]{}
    % \ead{email address}
    % \ead[url]{home page}
    % \fntext[label2]{}
    % \cortext[cor1]{}
    % \fntext[label3]{}



    %% use optional labels to link authors explicitly to addresses:
    %% \author[label1,label2]{}
    %% \affiliation[label1]{organization={},
    %%             addressline={},
    %%             city={},
    %%             postcode={},
    %%             state={},
    %%             country={}}
    %%
    %% \affiliation[label2]{organization={},
    %%             addressline={},
    %%             city={},
    %%             postcode={},
    %%             state={},
    %%             country={}}

    \author[THUDEM]{Hanyu Zhou}
    \author[THUDEM]{Yuxin Ren}

    \affiliation[THUDEM]
    {
        organization=
            { Department of Engineering Mechanices, Tsinghua Universiy},%Department and Organization
        addressline={},
        city={},
        postcode={},
        state={Beijing},
        country={China}}



    \begin{abstract}
        Text of abstract

    \end{abstract}

    % %%Graphical abstract
    % \begin{graphicalabstract}
    % %\includegraphics{grabs}
    % \end{graphicalabstract}

    %%Research highlights
    \begin{highlights}
        \item Research highlight 1
        \item Research highlight 2
    \end{highlights}

    \begin{keyword}
        %% keywords here, in the form: keyword \sep keyword

        %% PACS codes here, in the form: \PACS code \sep code

        %% MSC codes here, in the form: \MSC code \sep code
        %% or \MSC[2008] code \sep code (2000 is the default)

    \end{keyword}

\end{frontmatter}

%% \linenumbers

%% main text
\section{Introduction}
\label{sec:intro}

In computational fluid dynamics (CFD),
high-order numerical methods have the capability of
resolving complex flows effectively and efficiently,
which have been attracting great attention recently.
Popular high-order CFD methods, including discontinuous
Galerkin (DG) methods
\cite{reed1973triangularDG,
    BASSI1997251DG,
    BASSI1997267DG,
    cockburn1989DGII,
    cockburn2001rungeDG},
spectral volume
\cite{WANG2002210_SV}
and spectral difference
\cite{LIU2006780_SD} methods,
PnPm procedures
\cite{DUMBSER20088209_PNPM},
FR/CPR methods
\cite{huynh2007flux_FR,
    huynh2009reconstruction_FR,
    vincent2011new_FR,
    wang2009unifying_CPR},
and finite volume (FV) methods
\cite{wang2016compact_VR,
    wang2016compact1_VR,
    wang2017compact_VR,
    pan2018high_VR,
    zhang2019compact_VR,
    barth1990higher_FV,
    delanaye1999quadratic_FV,
    ollivier1997quasi_ENO,
    friedrich1998weighted_WENO,
    hu1999weighted_WENO,
    dumbser2007quadrature_WENO},
generally provides spacial discretization methods
which produce semi-discretized forms of the original
partial differential equations (PDEs).
The semi-discretized PDEs are
sets of first order ordinary
differential equations (ODEs),
which are usually further solved with
ODE integrators such as the
popular strong stability preserving
Runge-Kutta (SSPRK) methods
\cite{gottlieb2001strong_SSPRK}.

Although explicit ODE integrators
are simple and efficient in a wide range of
CFD problems,
the Courant-Friedrichs-Lewy (CFL) constraint
that limits physical time step in explicit
methods could make them inefficient in
notably inhomogeneous or anisotropic
transient flows,
such as wall-bounded turbulence.
Such inefficiency could be overcome by
applying implicit ODE methods with
sufficient stability.
Due to Dahlquist's second barrier
\cite{dahlquist1963special},
only second and first order multi-step ODE methods
could achieve $A$-stability, and
trapezoid rule not being $L$-stable,
only the $L$-stable
second-order backward differentiation formula (BDF2)
is extensively adopted in transient CFD problems.
Different from multi-step methods,
the single-step implicit Runge-Kutta (IRK) methods
with multiple internal stages
can achieve higher order of accuracy while
preserving stability \cite{butcher2016ODEBook}.
Among the IRK methods, fully coupled IRK methods
could achieve optimal order given number of stages,
but they require the solution of a nonlinear
system with its dimension multiple times larger
than the ODE, which could be especially
troublesome for its implementation in
CFD schemes.
Pazner and Persson
\cite{pazner2017stage}
made effort in efficiently solving
fully IRK methods with DG, and
Jameson \cite{jameson2017evaluation}
discussed how to adopt dual time stepping
into fully IRK.
As a result of the difficulties in the solution
of fully IRK methods,
singly diagonally implicit Runge-Kutta (SDIRK)
methods are more commonly used in CFD, for example in
\cite{wang2017compact_VR}.
SDIRK methods have lower-triangular butcher tableau,
enabling the stage values to be solved in a sequence.
As a special case of SDIRK,
ESDIRK methods are SDIRK with an explicit first stage,
which are constructed to be
stiffly accurate and $L$-stable
\cite{kennedy2003additiveARK,kvaerno2004singly}.
High-order ESDIRK schemes and
BDF2 have been tested in
\cite{
    bijl2002implicitBDFvESDIRK,
    wang2007implicitDGTests}
to solve flow problems,
whose results illustrate
better accuracy and higher efficiency
of high-order ESDIRK methods
compared to second order BDF2.

Apart from fully IRK and SDIRK methods,
another class of implicit RK methods,
mono implicit RK methods (MIRK)
\cite{cash1975classMIRKOrig}
have explicit internal stages and
puts all the implicitness into the final
stage, allowing the implicit system to
remain have the same number of dimensions
as the original ODE.
Cash and Signhal derived examples of
$A$-stable and $L$-stable high-order
MIRK methods in
\cite{cash1977clasMIRK1,cash1982monoMIRK2}.
Kulikov and Shindin presented a similar type
of method called nested implicit RK (NIRK)
\cite{kulikov2006familyNIRKOrig}.
Discussion was made on symmetry, stiff accuracy and
other advantageous properties of a series of Gauss type
NIRK methods.
\cite{kulikov2009adaptive}.
The major drawback of NIRK or MIRK schemes is that
the Jacobian matrices of the nonlinear algebraic problems
for each NIRK or MIRK step are
polynomials of the Jacobian of ODE's right hand side.
Cash and Singhal proposed to find MIRK methods whose
Jacobian could be factorized or approximate the Jacobian
with a factorization,
so that the Newton iteration
step could be solved by solving a series of successive linear
problems \cite{cash1982monoMIRK2}.
Kulikov and Shindin found certain factorization
approximation could sabotage the stability of
the method in
\cite{kulikov2009adaptive},
and analyzed how to choose the approximation of
Jacobian in
\cite{kulikov2007asymptotic}.
MIRK and NIRK methods are more attractive than SDIRK methods
for they require fewer inner stage solving.
Typical fourth order
stiffly accurate ESDIRK requires 5 implicit internal stages to be
solved,
while MIRK and NIRK could
solve only one implicit stage.


MIRK and NIRK methods have less
implicit stages than SDIRK methods,
which gives them potential to gain better efficiency in
large scale problems.
However, current literature has seldom explored
the application of MIRK or NIRK methods in
PDE solving.
Therefore, this paper aims to
derive an NIRK type ODE method suitable for high-order
CFD implementation,
and apply the method to flow problems.
(matrix free...)
\#\#\#\#

Paper's structure:...%TODO


\section{Hermite Interpolation Implicit Runge Kutta Method}
\label{sec:HIRK}

The acquiring of an NIRK method with
certain order of accuracy is usually based on
a certain integration method and
corresponding taylor expansion analysis,
as described in \cite{kulikov2006familyNIRKOrig}.
The present paper proposes a type of NIRK
derived with Hermite interpolation
(thus called HIRK),
which simplifies the analysis on
stage accuracy and provides an approach to
modify the scheme.

\newcommand{\uu}{\mathbf{u}}
\newcommand{\R}{\mathbf{R}}
\newcommand{\inc}{\mathrm\Delta}
\newcommand{\Tau}{\mathrm{T}}

Considering a general first order ODE about
$t\in[0,\infty)$ and $\uu\in \mathbb{R}^N$:
\begin{equation}
    \frac{d\uu}{dt} = \R(t, \uu)
\end{equation}
with $\uu^n$ as the known numerical solution at $t=t^n$ and
$t^{n+1} = t^{n} + \inc t$,
the HIRK method has the form:
\begin{subequations}
    \label{eq:HM3}
    \begin{align}
        \uu^{n+1} & = \uu^{n} +
        \inc t
        \left[
            b_1\R(t^{n,1}, \uu^n) +
            b_2\R(t^{n,2}, \uu^*) +
            b_3\R(t^{n,3}, \uu^{n+1})
        \right]   \label{eq:HM3-1} \\
        \uu^{*}   & =
        a_1\uu^{n} +
        a_2\uu^{n+1} +
        \inc t
        \left[
            d_1\R(t^{n,1}, \uu^n) +
            d_2\R(t^{n,3}, \uu^{n+1})
            \right] \label{eq:HM3-2}
    \end{align}
\end{subequations}
where $t^{n,i}=t^n+c_i\inc t$, and $c_1 = 0, c_3 = 1, c_2\in(0,1)$.

The only stage value besides endpoints is $\uu^*$.
The internal stage $\uu^*$ can be explicitly
calculated with \eqref{eq:HM3-2}, which is derived
directly from the cubic Hermite interpolation of $\uu$
on interval $[t^n,t^{n+1}]$ evaluated at
$t^{n,2}$, which result in the interpolation relation:
\begin{equation}
    \begin{aligned}
        a_2 & = 1 - a_1 = 3{c_2}^2 - 2 {c_2}^3 \\
        d_1 & = {c_2} - 2 {c_2}^2 + {c_2}^3    \\
        d_2 & = - {c_2}^2 + {c_2}^3            \\
    \end{aligned}
    \label{eq:interp}
\end{equation}
The first equation \eqref{eq:HM3-1} is
a numeric integration on interval $[t^n,t^{n+1}]$ with
polynomial nodes
$t^{n,1}=t^n,t^{n,2}=t^n+c_2\inc t,t^{n,3}=t^{n+1}$, which demands:
\begin{equation}
    \begin{aligned}
        b_1 & = \frac{1}{2} - \frac{1}{6{c_2}}     \\
        b_2 & = \frac{1}{6{c_2}(1-{c_2})}          \\
        b_3 & = \frac{1}{2} - \frac{1}{6(1-{c_2})} \\
    \end{aligned}
    \label{eq:integ}
\end{equation}
The Hermite interpolation gives \eqref{eq:HM3-2}
local truncation error $O(\inc t^4)$,
and the numeric integration gives \eqref{eq:HM3-1}
local truncation error $O(\inc t^3)$, therefore the
classic order of accuracy of HIRK \eqref{eq:HM3} is
3. If $c_2=1/2$, then the numeric integration \eqref{eq:HM3-2}
becomes a Gauss-Lobatto quadrature rule, which yields
a local truncation error of $O(\inc t^4)$, making
the scheme 4th order accurate.
Also, from the interpolation, no matter
the choice of $c_2$, HIRK has a stage order of
3, making it stiffly accurate.
As there is a family of HIRK methods decided by
a single parameter $c_2$,
here we denote them as HIRK($c_2$).


Reformulating \eqref{eq:HM3} into
a standard Runge-Kutta form yields a Butcher
tableau:
\begin{table}[htbp]
    \centering
    \begin{tabular}{c|ccc}
        0     & 0              & 0        & 0              \\
        $c_2$ & $d_1 + a_2b_1$ & $a_2b_2$ & $d_2 + a_2b_3$ \\
        1     & $b_1$          & $b_2$    & $b_3$          \\ \hline
              & $b_1$          & $b_2$    & $b_3$
    \end{tabular}
    \caption{Butcher tableau of \eqref{eq:HM3}}
    \label{tab:HM3Butcher}
\end{table}

From table \ref{tab:HM3Butcher} with the coefficients
decided with \eqref{eq:interp} and \eqref{eq:integ},
one can find that the 4th order accurate
HIRK($1/2$) is indeed the Lobatto IIIA method
of order 4 \cite{wanner1996solving}.
The classic order and stage order of HIRK could
also be evaluated from table \ref{tab:HM3Butcher} via
the simplifying assumptions.
Despite the formulation above only
provides an order degraded modification
of Lobatto IIIA type IRK method,
this modification will prove useful
in latter discussion.

If the quadrature rule in HIRK is
replaced with Gauss-Legendre rule,
the method immediately becomes a special case of the
Gauss type NIRK method of order 4
described in \cite{kulikov2006familyNIRKOrig}.
For large scale CFD application,
using 2 point Gauss-Legendre rule
would mean deriving the right hand side at
3 different stages iteratively.
Thus, the current HIRK method only considers
a 3 point Gauss-Lobatto type quadrature
(with the middle abscissa moved and order of accuracy reduced).



% \begin{equation}
%     \label{eq:HM3R}
%     \begin{aligned}
%         \uu^{n+1} & = \uu^{n} +
%         \inc t
%         \left(
%         b_1\R(t^{n,1}, \uu^n) +
%         b_2\R(t^{n,2}, \uu^*) +
%         b_3\R(t^{n,3}, \uu^{n+1})
%         \right) \\
%         \uu^{*}   & =
%         \uu^{n}  + 
%         \inc t
%         \left(
%         (d_1 + a_2b_1)\R(t^{n,1}, \uu^n) +
%         a_2b_2\R(t^{n,2}, \uu^*) +
%         (d_2 + a_2b_3)\R(t^{n,3}, \uu^{n+1})
%         \right)
%     \end{aligned}
% \end{equation}

\subsection{Linear Stability}

Following standard analysis based on Dahlquist's equation
$\frac{dy}{dt} = \lambda y$ \cite{wanner1996solving},
the stability function giving $y^{1}=R(h\lambda)y^0$
when applying HIRK is in the form:
\begin{equation}
    \label{eq:stabilityFunc}
    R(z) = -\frac{4\,z-2\,c_{2}\,z-c_{2}\,z^2+z^2+6}{2\,z+2\,c_{2}\,z-c_{2}\,z^2-6}
\end{equation}
which becomes the (2,2)-Pad{\'e} approximation when $c_2=1/2$ and HIRK
becomes Lobatto IIIA. The limit
\begin{equation}
    \lim_{z\rightarrow\infty}R(z) = \frac{1-c_2}{c_2}
\end{equation}
gives that a necessary condition for $A$-stability of
HIRK is $c_2 \in [1/2,1)$, and shows that HIRK
is unable to achieve $L$-stability.
Further analysis on \eqref{eq:stabilityFunc}
would confirm $c_2 \in [1/2,1)$ is a sufficient
condition for $A$-stability.

HIRK($1/2$) or Lobatto IIIA method is symmetric,
which is a preferable property when integrating
reversible systems,
but the symmetry could be considered harmful in CFD application.
Most CFD systems of interest are physically dissipative,
while for symmetric RK methods
$R(z) \rightarrow 1$ when $z \rightarrow \infty$,
which is more likely to preserve
spurious modes arising from spacial discretization.
Although HIRK cannot achieve $L$-stability
by simply adjusting $c_2$,
using a non-trivial value $c_2 > 1/2$ would still
produce $\lim_{z\rightarrow\infty}R(z)\in(0,1)$, which
is a useful property in simulation of dissipative systems.
With  $c_2 > 1/2$, stiff modes could better vanish over the time
steps, while $c_2 = 1/2$ tends to preserve them.


\subsection{Solving Strategy}

\newcommand{\Res}{\mathcal{R}}
\newcommand{\Jres}{\mathcal{J}}
\newcommand{\eye}{\mathbf{I}}
\newcommand{\J}{\mathbf{J}}

HIRK's Butcher tableau in table \ref{tab:HM3Butcher}
indicates that apart from the first stage,
the other two stages seem fully coupled,
but following the original formulation
of HIRK \eqref{eq:HM3} which originates from
interpolation and integration,
clearly the internal stage $\uu^*$ can be explicitly
expressed by $\uu^n, \uu^{n+1}$ with the interpolation
relation \eqref{eq:HM3-2}, and one only need
to solve \eqref{eq:HM3-1} implicitly.
Therefore, the first solving strategy this paper
considers is identical to the spirit of NIRK,
which solves the equation:
\begin{equation}
    \label{eq:eqFull}
    \uu^{n+1} -
    \left(\uu^{n} + \inc t
    \left[
        b_1\R(t^{n,1}, \uu^n) +
        b_2\R(t^{n,2}, \uu^*) +
        b_3\R(t^{n,3}, \uu^{n+1})
        \right]
    \right)  =  0
\end{equation}
For simplicity, we denote the residual of \eqref{eq:eqFull}
as:
\begin{equation}
    \uu^{n+1} -
    \left(\uu^{n} + \inc t
    \left[
        b_1\R(t^{n,1}, \uu^{n}) +
        b_2\R(t^{n,2}, \uu^{*}) +
        b_3\R(t^{n,3}, \uu^{n+1})
        \right]
    \right) \doteq \Res(\uu^{n+1})
\end{equation}
Considering $\uu^{n}$ is known,
and $\uu^{*}$ is explicitly expressed,
$\Res(\uu^{n+1})$ is considered only a
function of unknown $\uu^{n+1}$.
The Newton-Raphson method applied to
\eqref{eq:eqFull}'s solving would be
\begin{equation}
    \begin{aligned}
        \uu^{n+1,m+1}                  & =  \uu^{n+1,m} + \inc \uu^{n+1,m}, \\
        \frac{\partial \Res(\uu^{n+1,m})}
        {\uu^{n+1,m}} \inc \uu^{n+1,m} & = - \Res(\uu^{n+1,m})
    \end{aligned}
\end{equation}
and adding the pseudo time continuation
would be
\begin{equation}
    \label{eq:ntDtau}
    \begin{aligned}
        \uu^{n+1,m+1}            & =  \uu^{n+1,m} + \inc \uu^{n+1,m}, \\
        \left(
        \frac{\partial \Res(\uu^{n+1,m})}
        {\uu^{n+1,m}} + \inc t \Tau^{-1}
        \right) \inc \uu^{n+1,m} & = - \Res(\uu^{n+1,m})
    \end{aligned}
\end{equation}
where $\Tau=\mathrm{diag}(\tau_1,...\tau_N)$ is a diagonal matrix with
local pseudo time steps as its diagonal values.
The pseudo time continuation of Newton iteration
could be both understood as a relaxation of original
method for nonlinear stability,
or as the result of solving dual time stepping
method Jameson developed \cite{jameson1991time}.
In other words, \eqref{eq:ntDtau} is the result
of solving pseudo time evolution
$\frac{d\uu^{n+1}}{d\tau} = -\frac{\Res}{\inc t}$
with linearly implicit backward Euler method and
a local time stepping.
Such dual time stepping is prevalent in transient
flow solution due to the nonlinearity in
fluid systems.
However, pseudo time term could
cause trouble if we try to solve HIRK
of any MIRK type system with certain approaches, which
will be illustrated later.

The expanded form of residual's Jacobian
is
\begin{equation}
    \label{eq:fullJCB}
    \begin{aligned}
        \frac{\partial \Res(\uu^{n+1})}
        {\uu^{n+1}}
                     & = \eye - \inc t b_3 \J^{n+1} -
        \inc t b_2\J^*(a_2\eye +\inc t d_2 \J^{n+1})                                \\
                     & = \frac{d_2 + a_2b_3}{d_2}\eye
        -\frac{a_2b_3}{d_2}\left(
        \eye + \frac{d_2b_2}{b_3}\inc t\J^*
        \right)\left(
        \eye + \frac{d_2}{a_2}\inc t\J^{n+1}
        \right)                                                                     \\
        \text{with:} &                                                              \\
                     & \J^* = \frac{\partial \R(t^{n,2},\uu^*)}{\partial \uu^*},\ \
        \J^{n+1} = \frac{\partial \R(t^{n,3},\uu^{n+1})}{\partial \uu^{n+1}}
    \end{aligned}
\end{equation}
which is a quadratic polynomial of right-hand-sides'
Jacobian.
If the Jacobian matrices could be explicitly formed and
manipulated, solving \eqref{eq:ntDtau} would be straightforward.
But a lot of high order methods rely on matrix-free
Jacobian evaluation, thus solving the linear system
with its matrix in the form of \eqref{eq:fullJCB}
would be troublesome or impossible.
Even if one would like to use a matrix-less linear solver
like Krylov space solvers,
powerful matrix-free preconditioners like ILU(0) or
LUSGS would be unavailable.

The solution to the complexity of Jacobian
by Kulikov and Shindin
is using an approximate factorization
\cite{kulikov2006familyNIRKOrig,kulikov2009adaptive}.
For the forth order
Gauss type NIRK in \cite{kulikov2006familyNIRKOrig},
Kulikov and Shindin used $(\eye-\inc t /4 \J)^2$
as an approximation.
This paper considers the form
\begin{equation}
    \label{eq:factJCB}
    \begin{aligned}
        \frac{\partial \Res(\uu^{n+1})}
        {\uu^{n+1}}
         & \approx
        -\frac{a_2b_3}{d_2}\left(
        \eye + \frac{d_2b_2}{b_3}\inc t\J^*
        \right)\left(
        \eye + \frac{d_2}{a_2}\inc t\J^{n+1}
        \right)    \\
    \end{aligned}
\end{equation}
which is directly taken from the last term
in \eqref{eq:fullJCB}, and the omitted term
is identity matrix with coefficient $\frac{d_2 + a_2b_3}{d_2}>0$
for $c_2\in(0,1)$. Note that $d_2<0$ for any possible $c_2$.

Using a factorized form of approximate
Jacobian like \eqref{eq:factJCB} enables the use of
two successive matrix-free solvers to obtain
the increment for Newton iteration.

For practical CFD implementation,
pseudo time term is now considered.
In order to preserve the factorized form,
this paper finds using
\begin{equation}
    \label{eq:ntDtau_Fact}
    \begin{aligned}
        \uu^{n+1,m+1}    & =  \uu^{n+1,m} + \inc \uu^{n+1,m}, \\
        -\frac{a_2b_3}{d_2}\left(
        \eye + \frac{d_2b_2}{b_3}\inc t\J^*
        + \inc t \Tau^{-1}
        \right)\left(
        \eye + \frac{d_2}{a_2}\inc t\J^{n+1}
        \right)
        \inc \uu^{n+1,m} & = - \Res(\uu^{n+1,m})
    \end{aligned}
\end{equation}
as the pseudo time continued Newton iteration
satisfactory.
In the linear sense, using this this approximate
Jacobian and pseudo time stepping does not sabotage
the convergence of Newton iteration, which can
be shown by applying the iteration \eqref{eq:ntDtau_Fact}
to solving scalar ODE $\frac{dy}{dt} = \lambda y$.
For multi-dimensional linear ODEs, using a Jordan decomposition
would make the proof reduce to scalar equation. \#\#\#\#


% Due to the explicit nature of the internal 
% stage $\uu^*$, when solving nonlinear systems,
% the un-converged state of $\uu^{n+1}$ at 
% the beginning of iteration could put $\uu^*$
% far from the real solution, 
% causing the right-hand-side to behave bad
% and possibly make the iteration breakdown. 
% Therefore, this paper presents another approach of solving 
% HIRK step which is vital for nonlinear ODEs.

% In order to account for nonlinearity, 
% we forsake the explicit nature in the 
% determination of $\uu^*$ as described in \eqref{eq:HM3-2}, 
% which is an Hermite interpolation linear dependent 
% on $\uu^{n},\uu^{n+1},\R^n, \R^{n+1}$.

This paper also provides another kind of
solving strategy,
which forsakes the explicitness in \eqref{eq:HM3-2},
thus making $\uu^*$ the dof to be solved,
which is the case for a general IRK scheme.
The equation to solve would be:
\begin{equation}
    \begin{aligned}
                                  & \left\{
        \begin{array}[2]{ll}
            \Res(\uu^{n+1},\uu^{*})   & = 0 \\
            \Res^*(\uu^{n+1},\uu^{*}) & = 0 \\
        \end{array}
        \right.                                               \\
        \text{with}               &                           \\
        \Res(\uu^{n+1},\uu^{*})   & \doteq \uu^{n+1} - \left(
        \uu^{n} +
        \inc t
        \left[
            b_1\R(t^{n,1}, \uu^n) +
            b_2\R(t^{n,2}, \uu^*) +
            b_3\R(t^{n,3}, \uu^{n+1})
            \right]
        \right)                                               \\
        \Res^*(\uu^{n+1},\uu^{*}) & \doteq\uu^{*} - \left(
        a_1\uu^{n} +
        a_2\uu^{n+1} +
        \inc t
        \left[
            d_1\R(t^{n,1}, \uu^n) +
            d_2\R(t^{n,3}, \uu^{n+1})
            \right]
        \right)
    \end{aligned}
\end{equation}
Making $\uu^*$ unknown has two major drawbacks.
The first drawback is that additional memory
would be required for $\uu^*$'s storage.
Considering HIRK saves much space compared to
DIRK methods, and HIRK also requires some more space
for intermediate results even using explicit $\uu^*$ evaluation,
the first drawback would not be significant.
The second drawback is the increase in the dimension of
algebraic system.
Normally, the enlarged system can be solved
using appropriate blocking strategy,
for example in \cite{pazner2017stage}.
However, the current scheme takes a different form of
iteration which takes two sub-steps:
\begin{equation}
    \label{eq:intersolve}
    \begin{aligned}
        \uu^{*,m+1}   & = \uu^{*,m} - \left[
            \eye - \inc t \frac{\partial \Res^{*'}(\uu^{n+1,m},\uu^{*,m})}
            {\partial \uu^{*,m}}
            + \inc t \Tau^{-1}
            \right]
        \backslash \Res^{*'}(\uu^{n+1,m},\uu^{*,m}) \\
        \uu^{n+1,m+1} & = \uu^{n+1,m} - \left[
            \eye - \inc t \frac{\partial \Res^{}(\uu^{n+1,m},\uu^{*,m+1})}
            {\partial \uu^{n+1,m}}
            + \inc t \Tau^{-1}
            \right]
        \backslash \Res^{}(\uu^{n+1,m},\uu^{*,m+1}) \\
    \end{aligned}
\end{equation}
where the $\mathbf{A}\backslash \mathbf{b}$
notation means to solve the linear problem $\mathbf{A}\mathbf{x}=\mathbf{b}$ once.
The residual $\Res^{*'}$ is defined with:
\begin{equation}
    \Res^{*'}(\uu^{n+1},\uu^{*}) = \Res^*(\uu^{n+1},\uu^{*}) + \beta\Res(\uu^{n+1},\uu^{*})
\end{equation}
which serves as the residual preconditioned with transformation
\begin{equation*}
    \begin{bmatrix}
        \Res^{} \\
        \Res^{*'}
    \end{bmatrix} =
    \begin{bmatrix}
        \eye & 0 \\ \beta\eye & \eye
    \end{bmatrix}
    \begin{bmatrix}
        \Res^{} \\
        \Res^{*}
    \end{bmatrix}
\end{equation*}
with $\beta\in\mathbb{R}$.
In \cite{jameson2017evaluation} Jameson used the inverse of Butcher coefficients
for preconditioning, which makes off-diagonal blocks of
the Jacobian scalar.
That preconditioning could
be adopted in the current method,
but is not recommended for
possible instabilities in the presence of negative pressure fixing in
numeric tests. \#\#\#\#

The solving procedure \eqref{eq:intersolve} could be regarded as
successively updating $\uu^*$ with $\Res^{*'}$ and $\uu$
with $\Res^{}$, by using the latest values of the other DOF.
Within a linear context,
this would be a blocks Gauss-Seidel iteration
over the $2\times2$ blocks of system with each block being $N\times N$.
In other words,to solve:
\begin{equation*}
    \begin{bmatrix}
        \Res^{}(\uu^{n+1},\uu^{*}) \\
        \Res^{*'}(\uu^{n+1},\uu^{*})
    \end{bmatrix} = 0
\end{equation*}
the canonical quasi Newton iteration would need to solve
\begin{equation}
    \label{eq:fullCoupled}
    \begin{bmatrix}
        \frac{\partial\Res^{}(\uu^{n+1,m},\uu^{*,m})}{\partial\uu^{n+1,m}} + \inc t\Tau^{-1} &
        \frac{\partial\Res^{}(\uu^{n+1,m},\uu^{*,m})}{\partial\uu^{*,m}}                       \\
        \frac{\partial\Res^{*'}(\uu^{n+1,m},\uu^{*,m})}{\partial\uu^{n+1,m}}                 &
        \frac{\partial\Res^{*'}(\uu^{n+1,m},\uu^{*,m})}{\partial\uu^{*,m}} + \inc t\Tau^{-1}   \\
    \end{bmatrix}
    \begin{bmatrix}
        \inc\uu^{n+1,m} \\
        \inc\uu^{*,m}
    \end{bmatrix}
    =
    -\begin{bmatrix}
        \Res^{}(\uu^{n+1,m},\uu^{*,m}) \\
        \Res^{*'}(\uu^{n+1,m},\uu^{*,m})
    \end{bmatrix}
\end{equation}
to update both stage values concurrently.
The current method \eqref{eq:intersolve}
first solve the second block row of
\eqref{eq:fullCoupled} for the increment of $\uu^*$,
then solve the first block row
for the increment of $\uu^{n+1}$ using updated $\uu^*$.
The current solving strategy will
be referred to as successive solving in the following parts.

The omitting of off-diagonal relations in \eqref{eq:fullCoupled},
or the block nonlinear Gauss-Seidel handling on the top layer of
algorithm brings about extra error in iteration,
causing slow-down of iteration and possible divergence.
To analyze such behavior, the current research investigates
the impact of successive solving \eqref{eq:intersolve}
brought to solution of HIRK applied to linear problems
using precise linear solvers.
With a traditional quasi Newton iteration,
if pseudo time steps approaches infinity,
the iteration would converge in the first step in such
situation.
The introduction of successive solving \eqref{eq:intersolve}
renders this one-step-convergence impossible, thus
the convergence with successive solving will represent
all the deceleration effect caused by it.
The linear situation discussed could also be a linearization
of a non-linear ODE when the stage values converge near the
solution, and the instant convergence of Newton iteration would
be first order accurate.
In the linear or linearized scene,
the residual takes the form:
\begin{equation}
    \label{eq:linearized}
    \begin{aligned}
        \Res^{}(\uu^{n+1},\uu^{*})   & =
        \Res^{}_0 - \inc t b_2\J^*\uu^{*} + (\eye - \inc t b_3\J)\uu^{n+1} \\
        \Res^{*'}(\uu^{n+1},\uu^{*}) & =
        \Res^{*'}_0 + (\eye - \beta\inc t b_2\J^*)\uu^{*}
        + ((\beta-a_2)\eye - \inc t (\beta b_3 - d_2)\J)\uu^{n+1}
    \end{aligned}
\end{equation}
where $\J^*, \J$ are Jacobian of $\R$
at the solution of
$\uu^{*}, \uu^{n+1}$.
Applying \eqref{eq:intersolve} to
this linear form and assuming a infinite pseudo
time step,
following textbook analysis conduced on
Gauss-Seidel iteration,
the successive solving becomes a linear
fixed point iteration, with fixed point
mapping's matrix being
\begin{equation}
    \mathbf{B}_{SS}=\begin{bmatrix}
        \eye - \beta\inc t b_2\J^* & 0                   \\
        - \inc t b_2\J^*           & \eye - \inc t b_3\J \\
    \end{bmatrix}^{-1}
    \begin{bmatrix}
        0 & (\beta-a_2)\eye - \inc t (\beta b_3 - d_2)\J \\
        0 & 0                                            \\
    \end{bmatrix}
\end{equation}
Thus, convergence of the fixed point iteration equals to
the condition
\begin{equation}
    \label{eq:rhoGS}
    \begin{aligned}
         & \varUpsilon(\mathbf{B}_{SS}) \\
         & =\varUpsilon\left(
        -[\eye - \inc t b_3\J]^{-1}
        [- \inc t b_2\J^*]
        [\eye - \beta\inc t b_2\J^*]^{-1}
        [(\beta-a_2)\eye - \inc t (\beta b_3 - d_2)\J]
        \right)                         \\
         & < 1
    \end{aligned}
\end{equation}
where $\varUpsilon$ is spectral radius of matrix.
For arbitrary $\J,\J^*$, further analysis is difficult,
so we limit the situation to where $\J = \J^*$ is an acceptable
approximation, or the ODE is linear itself.
Using the Jordan form,
and assuming all the inverse are existent and precisely solved,
\eqref{eq:rhoGS} would become
\begin{equation}
    \label{eq:rhoGS1}
    \begin{aligned}
        \varrho_i =
        \left|
        -[1 -  b_3z_i]^{-1}
        [- b_2z_i]
        [1 - \beta b_2z_i]^{-1}
        [(\beta-a_2) - (\beta b_3 - d_2)z_i]
        \right| & < 1,\ \ \forall z_i = \inc t \lambda_i
    \end{aligned}
\end{equation}
where $\lambda_i$ is eigenvalues of $\J$.
By further assuming $\mathfrak{Re} z_i < 0$
which is true for stable semi-discretized
method used on bounded linear problems,
special cases were analyzed.
For $c_2=0.5, \beta=0.5$, it is found
$\varrho_i < 0.5$.
For $c_2=0.5, \beta=1$, it is found $\varrho_i < 0.42$.
For $c_2=0.55, \beta=0.5$, $\varrho_i$ could exceed 1.
For $c_2=0.55, \beta=1$, it is found $\varrho_i < 0.36$.
These analyses are trivial which involve finding maximal points
in the left complex plane and on the imaginary axis.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=3in]{pics/numSearchRho.png}
    \caption{Numerical search result }
    \label{fig:numSearchRho}
\end{figure}

Numerical search is conduced to find
\begin{equation}
    \varrho_m(\beta) = \max_{\forall i}(\varrho_i)
\end{equation}
whose result is shown in figure \ref{fig:numSearchRho}.
Figure \ref{fig:numSearchRho} indicates
at least for $c_2\in[0.5,0.6]$, $\varrho_m<1$
could be satisfied easily by adjusting $\beta$, therefore
achieving convergence in Gauss-Seidel iteration.
For optimal Gauss-Seidel convergence rate,
values of $\beta$ could be found by numeric searching
as shown in figure \ref{fig:numSearchRho}.
Figure \ref{fig:numSearchRho} also suggests
$c_2=0.5$ helps acquiring better convergence rage
in successive solving.

The current successive solving approach
differs from previous ones,
which only requires linear solutions of
the same dimension as the ODE.
This property makes HIRK's implementation
very similar to traditional DIRK or BDF methods,
thus taking less effort.




\section{Spacial Discretization Method}


\section{Numerical Tests}

\subsection{Isentropic Vortex}

\begin{figure}[htbp]
    \centering
    \begin{subfigure}{0.5\textwidth}
        \includegraphics[width=\textwidth]{pics/IV40_10steps_HM3LBT.png}
        \caption[]{HIRK $c_2=0.5$}
        \label{sfig:IV10Step_HM3LBT}
    \end{subfigure}\hfill
    \begin{subfigure}{0.5\textwidth}
        \includegraphics[width=\textwidth]{pics/IV40_10steps_HM3.png}
        \caption[]{HIRK $c_2=0.55$}
        \label{sfig:IV10Step_HM3}
    \end{subfigure}\\
    \begin{subfigure}{0.5\textwidth}
        \includegraphics[width=\textwidth]{pics/IV40_10steps_ESDIRK4.png}
        \caption[]{ESDIRK4}
        \label{sfig:IV10Step_ESDIRK4}
    \end{subfigure}\hfill
    \begin{subfigure}{0.5\textwidth}
        \includegraphics[width=\textwidth]{pics/IV40_10steps_BDF2.png}
        \caption[]{BDF2}
        \label{sfig:IV10Step_BDF2}
    \end{subfigure}
    \caption{Density distribution of isentropic vortex problem, with $\inc t = 1$ at $t=10$}
    \label{fig:IV10Step}
\end{figure}

\begin{figure}[htbp]
    \centering
    \begin{subfigure}{0.5\textwidth}
        \includegraphics[width=\textwidth]{pics/HM3_IV160_fig_1.png}
        \caption[]{Density error vs. time step size }
        \label{sfig:IVTests_Conv}
    \end{subfigure}\hfill
    \begin{subfigure}{0.5\textwidth}
        \includegraphics[width=\textwidth]{pics/HM3_IV160_fig_2.png}
        \caption[]{Density error vs. total cpu time consumption}
        \label{sfig:IVTests_Eff}
    \end{subfigure}
    \caption[]{Convergence and efficiency test with isentropic vortex problem}
    \label{fig:IVTests}
\end{figure}


\begin{figure}[htbp]
    \centering
    \begin{subfigure}{0.5\textwidth}
        \includegraphics[width=\textwidth]{pics/HM3_IV160_fig_21.png}
        \caption[]{Density error vs. effective iterations }
        \label{sfig:IVTests2_EffIt}
    \end{subfigure}\hfill
    \begin{subfigure}{0.5\textwidth}
        \includegraphics[width=\textwidth]{pics/HM3_IV160_fig_4.png}
        \caption[]{Cpu time vs. effective iterations}
        \label{sfig:IVTests2_CPUVEffIt}
    \end{subfigure}
    \caption[]{The impact of using iteration counting to measure total work}
    \label{fig:IVTests2}
\end{figure}

\subsection{Two Dimensional Vortex Shedding}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.7\textwidth]{pics/CylinderA1_Re2000_Mesh.png}
    \caption[]{Part of mesh used in $Re=2000$ vortex shedding problem}
    \label{fig:CylinderRe2000_Mesh}
\end{figure}

\begin{figure}[htbp]
    \centering
    \begin{subfigure}{0.5\textwidth}
        \includegraphics[width=\textwidth]{pics/CylinderA1_Re2000_HM3LBT.png}
        \caption[]{HIRK $c_2=0.5$}
        \label{sfig:CylinderRe2000_HM3LBT}
    \end{subfigure}\hfill
    \begin{subfigure}{0.5\textwidth}
        \includegraphics[width=\textwidth]{pics/CylinderA1_Re2000_HM3.png}
        \caption[]{HIRK $c_2=0.55$}
        \label{sfig:CylinderRe2000_HM3}
    \end{subfigure}
    \caption[]{Comparison of pressure distribution in $Re=2000$ vortex shedding problem}
    \label{fig:CylinderRe2000}
\end{figure}

\begin{figure}[htbp]
    \centering
    \begin{subfigure}{0.5\textwidth}
        \includegraphics[width=\textwidth]{pics/CylinderB1_Re1200_Mesh.png}
        \caption[]{Mesh}
        \label{sfig:CylinderRe1200Demo_Mesh}
    \end{subfigure}\hfill
    \begin{subfigure}{0.5\textwidth}
        \includegraphics[width=\textwidth]{pics/CylinderB1_Re1200.png}
        \caption[]{Vorticity distribution}
        \label{sfig:CylinderRe1200Demo_Vort}
    \end{subfigure}
    \caption[]{Mesh and a instance of z-vorticity distribution
        in $Re=1200$ vortex shedding problem}
    \label{fig:CylinderRe1200Demo}
\end{figure}



\begin{figure}[htbp]
    \centering
    \begin{subfigure}{0.5\textwidth}
        \includegraphics[width=\textwidth]{pics/Cylinder_fig14.png}
        \caption[]{Error vs. time step size}
        \label{sfig:CylinderRe1200_My_C}
    \end{subfigure}\hfill
    \begin{subfigure}{0.5\textwidth}
        \includegraphics[width=\textwidth]{pics/Cylinder_fig4.png}
        \caption[]{Error vs. effective iterations}
        \label{sfig:CylinderRe1200_My_E}
    \end{subfigure}
    \caption[]{Convergence and efficiency analysis with $\epsilon_{My}$ in $Re=1200$ vortex shedding problem}
    \label{fig:CylinderRe1200_My}
\end{figure}

\begin{figure}[htbp]
    \centering
    \begin{subfigure}{0.5\textwidth}
        \includegraphics[width=\textwidth]{pics/Cylinder_fig15.png}
        \caption[]{Error vs. time step size}
        \label{sfig:CylinderRe1200_Mx_C}
    \end{subfigure}\hfill
    \begin{subfigure}{0.5\textwidth}
        \includegraphics[width=\textwidth]{pics/Cylinder_fig5.png}
        \caption[]{Error vs. effective iterations}
        \label{sfig:CylinderRe1200_Mx_E}
    \end{subfigure}
    \caption[]{Convergence and efficiency analysis with $\epsilon_{Mx}$ in $Re=1200$ vortex shedding problem}
    \label{fig:CylinderRe1200_Mx}
\end{figure}

\begin{figure}[htbp]
    \centering
    \begin{subfigure}{0.5\textwidth}
        \includegraphics[width=\textwidth]{pics/Cylinder_fig13.png}
        \caption[]{Error vs. time step size}
        \label{sfig:CylinderRe1200_St_C}
    \end{subfigure}\hfill
    \begin{subfigure}{0.5\textwidth}
        \includegraphics[width=\textwidth]{pics/Cylinder_fig3.png}
        \caption[]{Error vs. effective iterations}
        \label{sfig:CylinderRe1200_St_E}
    \end{subfigure}
    \caption[]{Convergence and efficiency analysis with $\epsilon_{St}$ in $Re=1200$ vortex shedding problem}
    \label{fig:CylinderRe1200_St}
\end{figure}




\subsection{Double Mach Reflection}

\begin{figure}[htbp]
    \centering
    \begin{subfigure}{0.5\textwidth}
        \includegraphics[width=\textwidth]{pics/DM480_HM3LBT.png}
        \caption[]{HIRK $c_2=0.5$}
        \label{sfig:DM480_HM3LBT}
    \end{subfigure}\hfill
    \begin{subfigure}{0.5\textwidth}
        \includegraphics[width=\textwidth]{pics/DM480_HM3.png}
        \caption[]{HIRK $c_2=0.55$}
        \label{sfig:DM480_HM3}
    \end{subfigure}\\
    \begin{subfigure}{0.5\textwidth}
        \includegraphics[width=\textwidth]{pics/DM480_ESDIRK.png}
        \caption[]{ESDIRK4}
        \label{sfig:DM480_ESDIRK4}
    \end{subfigure}\hfill
    \begin{subfigure}{0.5\textwidth}
        \includegraphics[width=\textwidth]{pics/DM480_BDF.png}
        \caption[]{BDF2}
        \label{sfig:DM480_BDF2}
    \end{subfigure}
    \caption{Density distribution in double mach reflection problem}
    \label{fig:DM480}
\end{figure}

\section{Conclusion}


%% The Appendices part is started with the command \appendix;
%% appendix sections are then done as normal sections
%% \appendix

%% \section{}
%% \label{}

%% If you have bibdatabase file and want bibtex to generate the
%% bibitems, please use
%%
\bibliographystyle{elsarticle-num}
\bibliography{HM3DraftRefs.bib}

%% else use the following coding to input the bibitems directly in the
%% TeX file.

% \begin{thebibliography}{00}

%     %% \bibitem{label}
%     %% Text of bibliographic item

%     \bibitem{}

% \end{thebibliography}


\end{document}
\endinput
%%
%% End of file `elsarticle-template-num.tex'.
